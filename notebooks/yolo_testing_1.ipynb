{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9308b178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added /Users/cooper/Desktop/hydro-forecasting/src to Python path\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import torch \n",
    "import pandas as pd\n",
    "\n",
    "# Add src directory to Python path\n",
    "project_root = Path.cwd().parent  \n",
    "src_path = project_root / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "    print(f\"Added {src_path} to Python path\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2caabe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydro_forecasting.data.lazy_datamodule import HydroLazyDataModule\n",
    "from hydro_forecasting.preprocessing.grouped import GroupedPipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from hydro_forecasting.preprocessing.standard_scale import StandardScaleTransformer\n",
    "from hydro_forecasting.data.caravanify_parquet import (\n",
    "    CaravanifyParquet,\n",
    "    CaravanifyParquetConfig,\n",
    ")\n",
    "\n",
    "from hydro_forecasting.models.ealstm import LitEALSTM, EALSTMConfig\n",
    "from hydro_forecasting.model_evaluation.evaluators import TSForecastEvaluator\n",
    "from hydro_forecasting.model_evaluation.hp_from_yaml import hp_from_yaml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a545d504",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0df5d83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias': True,\n",
       " 'bidirectional': True,\n",
       " 'bidirectional_fusion': 'concat',\n",
       " 'dropout': 0.09091248360355031,\n",
       " 'future_hidden_size': 79,\n",
       " 'future_input_size': 9,\n",
       " 'future_layers': 3,\n",
       " 'group_identifier': 'gauge_id',\n",
       " 'hidden_size': 79,\n",
       " 'input_len': 36,\n",
       " 'input_size': 10,\n",
       " 'learning_rate': 0.0008706020878304854,\n",
       " 'num_layers': 3,\n",
       " 'output_len': 10,\n",
       " 'scheduler_factor': 0.5,\n",
       " 'scheduler_patience': 5,\n",
       " 'static_size': 10}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yaml_path = Path(\"/Users/cooper/Desktop/hydro-forecasting/notebooks/ealstm.yaml\")\n",
    "\n",
    "ealstm_hp = hp_from_yaml(\"ealstm\", yaml_path)\n",
    "ealstm_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0bd441f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_ca = CaravanifyParquetConfig(\n",
    "    attributes_dir=\"/Users/cooper/Desktop/CaravanifyParquet/CA/post_processed/attributes\",\n",
    "    timeseries_dir=\"/Users/cooper/Desktop/CaravanifyParquet/CA/post_processed/timeseries/csv\",\n",
    "    shapefile_dir=\"/Users/cooper/Desktop/CAMELS-CH/data/CARAVANIFY/CA/post_processed/shapefiles\",\n",
    "    gauge_id_prefix=\"CA\",\n",
    "    use_hydroatlas_attributes=True,\n",
    "    use_caravan_attributes=True,\n",
    "    use_other_attributes=True,\n",
    ")\n",
    "\n",
    "caravan_ca = CaravanifyParquet(config_ca)\n",
    "basin_ids = caravan_ca.get_all_gauge_ids()[:10]\n",
    "\n",
    "# basin_ids = [bid for bid in basin_ids if bid != \"CA_15030\"]\n",
    "\n",
    "caravan_ca.load_stations(basin_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f1055a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_us = CaravanifyParquetConfig(\n",
    "#     attributes_dir=\"/Users/cooper/Desktop/CaravanifyParquet/USA/post_processed/attributes\",\n",
    "#     timeseries_dir=\"/Users/cooper/Desktop/CaravanifyParquet/USA/post_processed/timeseries/csv\",\n",
    "#     shapefile_dir=\"/Users/cooper/Desktop/CAMELS-CH/data/CARAVANIFY/USA/post_processed/shapefiles\",\n",
    "#     gauge_id_prefix=\"USA\",\n",
    "#     use_hydroatlas_attributes=True,\n",
    "#     use_caravan_attributes=True,\n",
    "#     use_other_attributes=True,\n",
    "# )\n",
    "\n",
    "# caravan_us = CaravanifyParquet(config_us)\n",
    "# basin_ids += caravan_us.get_all_gauge_ids()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8755a7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "forcing_features = [\n",
    "    \"snow_depth_water_equivalent_mean\",\n",
    "    \"surface_net_solar_radiation_mean\",\n",
    "    \"surface_net_thermal_radiation_mean\",\n",
    "    \"potential_evaporation_sum_ERA5_LAND\",\n",
    "    \"potential_evaporation_sum_FAO_PENMAN_MONTEITH\",\n",
    "    \"temperature_2m_mean\",\n",
    "    \"temperature_2m_min\",\n",
    "    \"temperature_2m_max\",\n",
    "    \"total_precipitation_sum\",\n",
    "]\n",
    "\n",
    "static_features = [\n",
    "    # \"gauge_id\",\n",
    "    \"p_mean\",\n",
    "    \"area\",\n",
    "    \"ele_mt_sav\",\n",
    "    \"high_prec_dur\",\n",
    "    \"frac_snow\",\n",
    "    \"high_prec_freq\",\n",
    "    \"slp_dg_sav\",\n",
    "    \"cly_pc_sav\",\n",
    "    \"aridity_ERA5_LAND\",\n",
    "    \"aridity_FAO_PM\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b02753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_pipeline = GroupedPipeline(\n",
    "    Pipeline([(\"scaler\", StandardScaleTransformer())]),\n",
    "    columns=forcing_features,\n",
    "    group_identifier=\"gauge_id\",\n",
    ")\n",
    "\n",
    "target_pipeline = GroupedPipeline(\n",
    "    Pipeline([(\"scaler\", StandardScaleTransformer())]),\n",
    "    columns=[\"streamflow\"],\n",
    "    group_identifier=\"gauge_id\",\n",
    ")\n",
    "\n",
    "static_pipeline = Pipeline([(\"scaler\", StandardScaleTransformer())])\n",
    "\n",
    "preprocessing_config = {\n",
    "    \"features\": {\"pipeline\": feature_pipeline},\n",
    "    \"target\": {\"pipeline\": target_pipeline},\n",
    "    \"static_features\": {\"pipeline\": static_pipeline, \"columns\": static_features},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34197fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ STARTING PREPROCESSING PIPELINE ================\n",
      "\n",
      "================ LOADING STATIC ATTRIBUTES ================\n",
      "INFO: Attempting to load static attributes for 10 gauge IDs\n",
      "INFO: Processing static attributes for region 'CA'\n",
      "INFO: Loaded caravan attributes for 10 gauges in CA\n",
      "INFO: Loaded hydroatlas attributes for 10 gauges in CA\n",
      "INFO: Loaded other attributes for 10 gauges in CA\n",
      "INFO: Horizontally merging 3 attribute files for region 'CA'\n",
      "INFO: Vertically stacking attribute data from 1 regions\n",
      "SUCCESS: Loaded and merged static attributes for 10 unique basins from 3 files across 1 regions.\n",
      "INFO: Successfully loaded static attributes for 10 basins.\n",
      "\n",
      "================ FITTING PREPROCESSING PIPELINES ================\n",
      "INFO: Loading time series data for pipeline fitting...\n",
      "INFO: Loaded time series data for 10 basins\n",
      "INFO: Split time series data into train (33798), val (16896), test (16910)\n",
      "INFO: Fitted 3 pipelines\n",
      "\n",
      "================ PROCESSING BASIN TIME SERIES ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing basins: 100%|██████████| 10/10 [00:00<00:00, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ PROCESSING STATIC ATTRIBUTES ================\n",
      "INFO: Processing static attributes...\n",
      "SUCCESS: Saved transformed static attributes for 9 basins to /Users/cooper/Desktop/hydro-forecasting/tests/yolo_6/processed_static_data.parquet\n",
      "\n",
      "================ PROCESSING SUMMARY ================\n",
      "SUCCESS: Completed processing 9 of 10 basins\n",
      "WARNING: 1 basins excluded due to quality issues\n",
      "INFO: Created training dataset with 32429 samples\n",
      "INFO: Created validation dataset with 16435 samples\n",
      "INFO: Created test dataset with 16249 samples\n"
     ]
    }
   ],
   "source": [
    "region_time_series_base_dirs = {\n",
    "    \"CA\": \"/Users/cooper/Desktop/CaravanifyParquet/CA/post_processed/timeseries/csv/CA\",\n",
    "    \"USA\": \"/Users/cooper/Desktop/CaravanifyParquet/USA/post_processed/timeseries/csv/USA\",\n",
    "}\n",
    "\n",
    "region_static_attributes_base_dirs = {\n",
    "    \"CA\": \"/Users/cooper/Desktop/CaravanifyParquet/CA/post_processed/attributes/CA\",\n",
    "    \"USA\": \"/Users/cooper/Desktop/CaravanifyParquet/USA/post_processed/attributes/USA\",\n",
    "}\n",
    "\n",
    "datamodule = HydroLazyDataModule(\n",
    "    region_time_series_base_dirs=region_time_series_base_dirs,\n",
    "    region_static_attributes_base_dirs=region_static_attributes_base_dirs,\n",
    "    path_to_preprocessing_output_directory=\"/Users/cooper/Desktop/hydro-forecasting/tests/yolo_6\",\n",
    "    group_identifier=\"gauge_id\",\n",
    "    batch_size=2048,\n",
    "    input_length=ealstm_hp[\"input_len\"],\n",
    "    output_length=ealstm_hp[\"output_len\"],\n",
    "    forcing_features=forcing_features,\n",
    "    static_features=static_features,\n",
    "    target=\"streamflow\",\n",
    "    preprocessing_configs=preprocessing_config,\n",
    "    num_workers=4,\n",
    "    min_train_years=5,\n",
    "    train_prop=0.5,\n",
    "    val_prop=0.25,\n",
    "    test_prop=0.25,\n",
    "    max_imputation_gap_size=5,\n",
    "    list_of_gauge_ids_to_process=basin_ids,\n",
    "    is_autoregressive=True,\n",
    "    files_per_batch=20,\n",
    ")\n",
    "\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc06754",
   "metadata": {},
   "source": [
    "## Verify static data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a807898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset size: 16249\n",
      "Getting sample at index 1654...\n",
      "\n",
      "--- Checking for NaNs in sample tensors ---\n",
      "Tensor'X' shape: torch.Size([36, 10]), Contains NaNs: False\n",
      "  Sample tensor 'X': tensor([[-0.6782, -0.8469, -0.8102,  0.5967, -0.8725,  0.9365, -0.4239, -0.4371,\n",
      "         -0.2749, -0.5279],\n",
      "        [-0.6950, -0.8764, -0.8102,  0.6090, -0.9294,  1.1605, -0.4695, -0.4624,\n",
      "         -0.4882,  0.8459],\n",
      "        [-0.7062, -0.9207, -0.9600,  0.7004, -1.0301,  0.4864, -1.0457, -0.8347,\n",
      "         -1.2916,  0.4341],\n",
      "        [-0.7229, -0.8519, -0.8851,  0.7068, -0.8755, -0.4745, -1.2536, -1.4113,\n",
      "         -1.3374, -0.6357],\n",
      "        [-0.7341, -0.9059, -0.8768,  0.7066, -0.8907, -0.1430, -1.0498, -1.4568,\n",
      "         -1.5299, -0.6357]])\n",
      "Tensor'y' shape: torch.Size([10]), Contains NaNs: False\n",
      "  Sample tensor 'y': tensor([-0.7006, -0.6894, -0.6782, -0.6671, -0.6726])\n",
      "Tensor'static' shape: torch.Size([10]), Contains NaNs: False\n",
      "  Sample tensor 'static': tensor([-0.2210,  2.7662,  2.5964,  0.7564, -0.9938])\n",
      "Tensor'future' shape: torch.Size([10, 9]), Contains NaNs: False\n",
      "  Sample tensor 'future': tensor([[-0.7782, -0.7354,  0.9934, -0.6382,  0.0981, -0.4415, -0.8509, -1.2802,\n",
      "         -0.6385],\n",
      "        [-0.7241, -0.7437,  0.9935, -0.5909, -0.2664, -0.3774, -0.7821, -1.1646,\n",
      "         -0.6385],\n",
      "        [-0.7536, -0.7271,  0.9937, -0.7892,  1.0152, -0.5408, -0.6779, -0.9752,\n",
      "         -0.6246],\n",
      "        [-0.7585, -0.8019,  0.9984, -0.8315,  1.1635, -0.6691, -0.6323, -0.6901,\n",
      "         -0.3427],\n",
      "        [-0.6848, -0.8102,  1.0059, -0.5912, -0.2669, -0.5936, -0.6718, -0.7213,\n",
      "         -0.6219]])\n",
      "Item 'gauge_id' is not a tensor (type: <class 'str'>)\n",
      "Item 'input_end_date' is not a tensor (type: <class 'int'>)\n"
     ]
    }
   ],
   "source": [
    "test_dataset = datamodule.test_dataset\n",
    "if not test_dataset:\n",
    "    print(\"Test dataset not found.\")\n",
    "elif len(test_dataset) == 0:\n",
    "    print(\"Test dataset is empty.\")\n",
    "else:\n",
    "    print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "    # --- Get a Sample ---\n",
    "    sample_index = 1654\n",
    "    print(f\"Getting sample at index {sample_index}...\")\n",
    "    try:\n",
    "        sample = test_dataset[sample_index]\n",
    "\n",
    "        # --- Check for NaNs in the Sample Tensors ---\n",
    "        print(\"\\n--- Checking for NaNs in sample tensors ---\")\n",
    "        for key, tensor in sample.items():\n",
    "            if isinstance(tensor, torch.Tensor):\n",
    "                has_nan = torch.isnan(tensor).any().item()\n",
    "                print(f\"Tensor'{key}' shape: {tensor.shape}, Contains NaNs: {has_nan}\")\n",
    "                print(f\"  Sample tensor '{key}': {tensor[:5]}\")\n",
    "                if has_nan:\n",
    "                    # Optional: Print where NaNs occur\n",
    "                    nan_indices = torch.nonzero(torch.isnan(tensor))\n",
    "                    print(f\"  NaN indices in '{key}': {nan_indices.tolist()[:5]}...\") # Print first 5\n",
    "            else:\n",
    "                print(f\"Item '{key}' is not a tensor (type: {type(tensor)})\")\n",
    "\n",
    "    except IndexError:\n",
    "        print(f\"Error: Index {sample_index} out of bounds for dataset size {len(test_dataset)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while getting or checking the sample: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5525f5",
   "metadata": {},
   "source": [
    "## Let's try training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74eb05bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = datamodule.input_length\n",
    "output_length = datamodule.output_length\n",
    "\n",
    "config = EALSTMConfig(**ealstm_hp)\n",
    "\n",
    "\n",
    "# Instantiate the Lightning module.\n",
    "model = LitEALSTM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65b384c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: prepare_data() has already been run; skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type     | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | mse_criterion | MSELoss  | 0      | train\n",
      "1 | model         | BiEALSTM | 191 K  | train\n",
      "---------------------------------------------------\n",
      "191 K     Trainable params\n",
      "0         Non-trainable params\n",
      "191 K     Total params\n",
      "0.767     Total estimated model params size (MB)\n",
      "58        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Created training dataset with 32429 samples\n",
      "INFO: Created validation dataset with 16435 samples\n",
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]NaNs found in target tensor y for index 1652\n",
      "NaNs found in target tensor y for index 1653\n",
      "NaNs found in target tensor y for index 1654\n",
      "NaNs found in target tensor y for index 1655\n",
      "NaNs found in target tensor y for index 1656\n",
      "NaNs found in target tensor y for index 1657\n",
      "NaNs found in target tensor y for index 1658\n",
      "NaNs found in target tensor y for index 1659\n",
      "NaNs found in target tensor y for index 1660\n",
      "NaNs found in target tensor y for index 1661\n",
      "NaNs found in target tensor y for index 10075                              \n",
      "NaNs found in target tensor y for index 10076\n",
      "NaNs found in target tensor y for index 10077\n",
      "NaNs found in target tensor y for index 10078\n",
      "NaNs found in target tensor y for index 10079\n",
      "NaNs found in target tensor y for index 10080\n",
      "NaNs found in target tensor y for index 10081\n",
      "NaNs found in target tensor y for index 10082\n",
      "NaNs found in target tensor y for index 10083\n",
      "NaNs found in target tensor y for index 10084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/cooper/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/cooper/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/hydro-forecasting/src/hydro_forecasting/data/lazy_datamodule.py\", line 3, in <module>\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/hydro-forecasting/src/hydro_forecasting/data/lazy_datamodule.py\", line 3, in <module>\n",
      "    import pytorch_lightning as pl\n",
      "  File \"/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/pytorch_lightning/__init__.py\", line 27, in <module>\n",
      "    import pytorch_lightning as pl\n",
      "    from pytorch_lightning.callbacks import Callback  # noqa: E402\n",
      "    ^^  File \"/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/pytorch_lightning/__init__.py\", line 25, in <module>\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/__init__.py\", line 14, in <module>\n",
      "    from pytorch_lightning.callbacks.batch_size_finder import BatchSizeFinder\n",
      "  File \"/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/batch_size_finder.py\", line 27, in <module>\n",
      "    from lightning_fabric.utilities.seed import seed_everything  # noqa: E402\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/lightning_fabric/__init__.py\", line 35, in <module>\n",
      "    from pytorch_lightning.tuner.batch_size_scaling import _scale_batch_size\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1091, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1191, in get_data\n",
      "KeyboardInterrupt\n",
      "    from lightning_fabric.fabric import Fabric  # noqa: E402\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/lightning_fabric/fabric.py\", line 40, in <module>\n",
      "    from lightning_fabric.loggers import Logger\n",
      "  File \"/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/lightning_fabric/loggers/__init__.py\", line 15, in <module>\n",
      "    from lightning_fabric.loggers.tensorboard import TensorBoardLogger  # noqa: F401\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/lightning_fabric/loggers/tensorboard.py\", line 31, in <module>\n",
      "    from lightning_fabric.wrappers import _unwrap_objects\n",
      "  File \"/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/lightning_fabric/wrappers.py\", line 33, in <module>\n",
      "    from torch._dynamo import OptimizedModule\n",
      "  File \"/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/torch/_dynamo/__init__.py\", line 3, in <module>\n",
      "    from . import convert_frame, eval_frame, resume_execution\n",
      "  File \"/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 33, in <module>\n",
      "    from torch._dynamo.symbolic_convert import TensorifyState\n",
      "  File \"/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 30, in <module>\n",
      "    from . import config, exc, logging as torchdynamo_logging, trace_rules, variables\n",
      "  File \"/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py\", line 46, in <module>\n",
      "    from .variables import (\n",
      "  File \"/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/__init__.py\", line 2, in <module>\n",
      "    from .builtin import BuiltinVariable\n",
      "  File \"/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py\", line 53, in <module>\n",
      "    from .ctx_manager import EventVariable, StreamVariable\n",
      "  File \"/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/ctx_manager.py\", line 22, in <module>\n",
      "    from .functions import (\n",
      "  File \"/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py\", line 33, in <module>\n",
      "    from torch.distributed.fsdp._fully_shard import _fsdp_param_group\n",
      "  File \"/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/__init__.py\", line 1, in <module>\n",
      "    from ._flat_param import FlatParameter as FlatParameter\n",
      "  File \"/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py\", line 31, in <module>\n",
      "    from torch.distributed.fsdp._common_utils import (\n",
      "  File \"/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py\", line 38, in <module>\n",
      "    from .api import (\n",
      "  File \"/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/api.py\", line 291, in <module>\n",
      "    @dataclass\n",
      "     ^^^^^^^^^\n",
      "  File \"/Users/cooper/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/dataclasses.py\", line 1275, in dataclass\n",
      "    return wrap(cls)\n",
      "           ^^^^^^^^^\n",
      "  File \"/Users/cooper/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/dataclasses.py\", line 1265, in wrap\n",
      "    return _process_class(cls, init, repr, eq, order, unsafe_hash,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/dataclasses.py\", line 1083, in _process_class\n",
      "    _set_new_attribute(cls, '__repr__', _repr_fn(flds, globals))\n",
      "                                        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/dataclasses.py\", line 628, in _repr_fn\n",
      "    fn = _create_fn('__repr__',\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/dataclasses.py\", line 473, in _create_fn\n",
      "    exec(txt, globals, ns)\n",
      "  File \"<string>\", line 0, in <module>\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/cooper/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/torch/__init__.py\", line 405, in <module>\n",
      "    from torch._C import *  # noqa: F403\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 463, in _lock_unlock_module\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Please call `iter(combined_loader)` first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1056\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1055\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:208\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msetup_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.skip:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:275\u001b[39m, in \u001b[36m_FitLoop.setup_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28mself\u001b[39m._data_fetcher.setup(combined_loader)\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# creates the iterator inside the fetcher\u001b[39;00m\n\u001b[32m    276\u001b[39m max_batches = sized_len(combined_loader)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py:105\u001b[39m, in \u001b[36m_PrefetchDataFetcher.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[33m\"\u001b[39m\u001b[33m_PrefetchDataFetcher\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__iter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    107\u001b[39m         \u001b[38;5;66;03m# ignore pre-fetching, it's not necessary\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py:52\u001b[39m, in \u001b[36m_DataFetcher.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[33m\"\u001b[39m\u001b[33m_DataFetcher\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28mself\u001b[39m.iterator = \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcombined_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m     \u001b[38;5;28mself\u001b[39m.reset()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py:351\u001b[39m, in \u001b[36mCombinedLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    350\u001b[39m iterator = \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;28mself\u001b[39m.flattened, \u001b[38;5;28mself\u001b[39m._limits)\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[38;5;28mself\u001b[39m._iterator = iterator\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py:92\u001b[39m, in \u001b[36m_MaxSizeCycle.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Self:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__iter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     \u001b[38;5;28mself\u001b[39m._consumed = [\u001b[38;5;28;01mFalse\u001b[39;00m] * \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.iterables)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py:43\u001b[39m, in \u001b[36m_ModeIterator.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Self:\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[38;5;28mself\u001b[39m.iterators = [\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m iterable \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iterables]\n\u001b[32m     44\u001b[39m     \u001b[38;5;28mself\u001b[39m._idx = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:486\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    485\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m     \u001b[38;5;28mself\u001b[39m._iterator = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:422\u001b[39m, in \u001b[36mDataLoader._get_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    421\u001b[39m \u001b[38;5;28mself\u001b[39m.check_worker_number_rationality()\n\u001b[32m--> \u001b[39m\u001b[32m422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1146\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter.__init__\u001b[39m\u001b[34m(self, loader)\u001b[39m\n\u001b[32m   1140\u001b[39m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[32m   1141\u001b[39m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[32m   1142\u001b[39m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[32m   1143\u001b[39m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[32m   1144\u001b[39m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[32m   1145\u001b[39m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1146\u001b[39m \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1147\u001b[39m \u001b[38;5;28mself\u001b[39m._index_queues.append(index_queue)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/multiprocessing/process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/multiprocessing/context.py:224\u001b[39m, in \u001b[36mProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mProcess\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/multiprocessing/context.py:289\u001b[39m, in \u001b[36mSpawnProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_spawn_posix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/multiprocessing/popen_spawn_posix.py:32\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mself\u001b[39m._fds = []\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/multiprocessing/popen_fork.py:19\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mself\u001b[39m.finalizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/multiprocessing/popen_spawn_posix.py:62\u001b[39m, in \u001b[36mPopen._launch\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m, closefd=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m         \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      3\u001b[39m trainer = pl.Trainer(\n\u001b[32m      4\u001b[39m     max_epochs=\u001b[32m1\u001b[39m,\n\u001b[32m      5\u001b[39m     accelerator=\u001b[33m\"\u001b[39m\u001b[33mgpu\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     devices=\u001b[32m1\u001b[39m,\n\u001b[32m      7\u001b[39m )\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:61\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     59\u001b[39m signal.signal(signal.SIGINT, signal.SIG_IGN)\n\u001b[32m     60\u001b[39m _interrupt(trainer, exception)\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_teardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m launcher = trainer.strategy.launcher\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1039\u001b[39m, in \u001b[36mTrainer._teardown\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1037\u001b[39m \u001b[38;5;66;03m# loop should never be `None` here but it can because we don't know the trainer stage with `ddp_spawn`\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1039\u001b[39m     \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mteardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1040\u001b[39m \u001b[38;5;28mself\u001b[39m._logger_connector.teardown()\n\u001b[32m   1041\u001b[39m \u001b[38;5;28mself\u001b[39m._signal_connector.teardown()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:502\u001b[39m, in \u001b[36m_FitLoop.teardown\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    500\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mteardown\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    501\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m502\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mteardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    503\u001b[39m         \u001b[38;5;28mself\u001b[39m._data_fetcher = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    504\u001b[39m     \u001b[38;5;28mself\u001b[39m.epoch_loop.teardown()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py:80\u001b[39m, in \u001b[36m_DataFetcher.teardown\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mteardown\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._combined_loader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     82\u001b[39m         \u001b[38;5;28mself\u001b[39m._combined_loader.reset()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py:142\u001b[39m, in \u001b[36m_PrefetchDataFetcher.reset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m     \u001b[38;5;28mself\u001b[39m.batches = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py:76\u001b[39m, in \u001b[36m_DataFetcher.reset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# teardown calls `reset()`, and if it happens early, `combined_loader` can still be None\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._combined_loader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28mself\u001b[39m.length = \u001b[43msized_len\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcombined_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28mself\u001b[39m.done = \u001b[38;5;28mself\u001b[39m.length == \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/lightning_fabric/utilities/data.py:52\u001b[39m, in \u001b[36msized_len\u001b[39m\u001b[34m(dataloader)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Try to get the length of an object, return ``None`` otherwise.\"\"\"\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     51\u001b[39m     \u001b[38;5;66;03m# try getting the length\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     length = \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore [arg-type]\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[32m     54\u001b[39m     length = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py:358\u001b[39m, in \u001b[36mCombinedLoader.__len__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    356\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute the number of batches.\"\"\"\u001b[39;00m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m358\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mPlease call `iter(combined_loader)` first.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._iterator)\n",
      "\u001b[31mRuntimeError\u001b[39m: Please call `iter(combined_loader)` first."
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04f3d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_and_datamodules = {\n",
    "    \"EALSTM\": (model, datamodule),\n",
    "}\n",
    "\n",
    "evaluator = TSForecastEvaluator(\n",
    "    horizons=list(range(1, output_length + 1)),\n",
    "    models_and_datamodules=models_and_datamodules,\n",
    "    trainer_kwargs={\n",
    "        \"accelerator\": \"cpu\",\n",
    "        \"devices\": 1,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f5de30",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluator.test_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f23c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"EALSTM\"][\"df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8f78d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
