{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9308b178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added /Users/cooper/Desktop/hydro-forecasting/src to Python path\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src directory to Python path\n",
    "project_root = Path.cwd().parent  \n",
    "src_path = project_root / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "    print(f\"Added {src_path} to Python path\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2caabe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydro_forecasting.data.lazy_datamodule import HydroLazyDataModule\n",
    "from hydro_forecasting.preprocessing.grouped import GroupedPipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from hydro_forecasting.preprocessing.standard_scale import StandardScaleTransformer\n",
    "from hydro_forecasting.data.caravanify_parquet import (\n",
    "    CaravanifyParquet,\n",
    "    CaravanifyParquetConfig,\n",
    ")\n",
    "\n",
    "from hydro_forecasting.models.tide import LitTiDE, TiDEConfig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a545d504",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0bd441f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_ca = CaravanifyParquetConfig(\n",
    "    attributes_dir=\"/Users/cooper/Desktop/CaravanifyParquet/CA/post_processed/attributes\",\n",
    "    timeseries_dir=\"/Users/cooper/Desktop/CaravanifyParquet/CA/post_processed/timeseries/csv\",\n",
    "    shapefile_dir=\"/Users/cooper/Desktop/CAMELS-CH/data/CARAVANIFY/CA/post_processed/shapefiles\",\n",
    "    gauge_id_prefix=\"CA\",\n",
    "    use_hydroatlas_attributes=True,\n",
    "    use_caravan_attributes=True,\n",
    "    use_other_attributes=True,\n",
    ")\n",
    "\n",
    "caravan_ca = CaravanifyParquet(config_ca)\n",
    "basin_ids = caravan_ca.get_all_gauge_ids()[:10]\n",
    "\n",
    "# basin_ids = [bid for bid in basin_ids if bid != \"CA_15030\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f1055a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_us = CaravanifyParquetConfig(\n",
    "    attributes_dir=\"/Users/cooper/Desktop/CaravanifyParquet/USA/post_processed/attributes\",\n",
    "    timeseries_dir=\"/Users/cooper/Desktop/CaravanifyParquet/USA/post_processed/timeseries/csv\",\n",
    "    shapefile_dir=\"/Users/cooper/Desktop/CAMELS-CH/data/CARAVANIFY/USA/post_processed/shapefiles\",\n",
    "    gauge_id_prefix=\"USA\",\n",
    "    use_hydroatlas_attributes=True,\n",
    "    use_caravan_attributes=True,\n",
    "    use_other_attributes=True,\n",
    ")\n",
    "\n",
    "caravan_us = CaravanifyParquet(config_us)\n",
    "basin_ids += caravan_us.get_all_gauge_ids()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10f3e392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CA_15013',\n",
       " 'CA_15016',\n",
       " 'CA_15020',\n",
       " 'CA_15022',\n",
       " 'CA_15025',\n",
       " 'CA_15030',\n",
       " 'CA_15034',\n",
       " 'CA_15039',\n",
       " 'CA_15040',\n",
       " 'CA_15044',\n",
       " 'USA_01013500',\n",
       " 'USA_01022500',\n",
       " 'USA_01030500',\n",
       " 'USA_01031500',\n",
       " 'USA_01047000',\n",
       " 'USA_01052500',\n",
       " 'USA_01054200',\n",
       " 'USA_01055000',\n",
       " 'USA_01057000',\n",
       " 'USA_01073000']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basin_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8755a7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "forcing_features = [\n",
    "    \"snow_depth_water_equivalent_mean\",\n",
    "    \"surface_net_solar_radiation_mean\",\n",
    "    \"surface_net_thermal_radiation_mean\",\n",
    "    \"potential_evaporation_sum_ERA5_LAND\",\n",
    "    \"potential_evaporation_sum_FAO_PENMAN_MONTEITH\",\n",
    "    \"temperature_2m_mean\",\n",
    "    \"temperature_2m_min\",\n",
    "    \"temperature_2m_max\",\n",
    "    \"total_precipitation_sum\",\n",
    "]\n",
    "\n",
    "static_features = [\n",
    "    # \"gauge_id\",\n",
    "    \"p_mean\",\n",
    "    \"area\",\n",
    "    \"ele_mt_sav\",\n",
    "    \"high_prec_dur\",\n",
    "    \"frac_snow\",\n",
    "    \"high_prec_freq\",\n",
    "    \"slp_dg_sav\",\n",
    "    \"cly_pc_sav\",\n",
    "    \"aridity_ERA5_LAND\",\n",
    "    \"aridity_FAO_PM\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b02753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_pipeline = GroupedPipeline(\n",
    "    Pipeline([(\"scaler\", StandardScaleTransformer())]),\n",
    "    columns=forcing_features,\n",
    "    group_identifier=\"gauge_id\",\n",
    ")\n",
    "\n",
    "target_pipeline = GroupedPipeline(\n",
    "    Pipeline([(\"scaler\", StandardScaleTransformer())]),\n",
    "    columns=[\"streamflow\"],\n",
    "    group_identifier=\"gauge_id\",\n",
    ")\n",
    "\n",
    "static_pipeline = Pipeline([(\"scaler\", StandardScaleTransformer())])\n",
    "\n",
    "preprocessing_config = {\n",
    "    \"features\": {\"pipeline\": feature_pipeline},\n",
    "    \"target\": {\"pipeline\": target_pipeline},\n",
    "    \"static_features\": {\"pipeline\": static_pipeline, \"columns\": static_features},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34197fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ STARTING PREPROCESSING PIPELINE ================\n",
      "\n",
      "================ LOADING STATIC ATTRIBUTES ================\n",
      "INFO: Attempting to load static attributes for 20 gauge IDs\n",
      "INFO: Loaded static attributes for 20 unique basins from 6 files.\n",
      "INFO: Successfully loaded static attributes for 20 basins.\n",
      "\n",
      "================ FITTING PREPROCESSING PIPELINES ================\n",
      "INFO: Loading time series data for pipeline fitting...\n",
      "INFO: Loaded time series data for 20 basins\n",
      "INFO: Split time series data into train (96211), val (48099), test (48121)\n",
      "INFO: Fitted 3 pipelines\n",
      "\n",
      "================ PROCESSING BASIN TIME SERIES ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing basins: 100%|██████████| 20/20 [00:01<00:00, 17.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ PROCESSING STATIC ATTRIBUTES ================\n",
      "INFO: Processing static attributes...\n",
      "SUCCESS: Saved transformed static attributes for 19 basins to /Users/cooper/Desktop/hydro-forecasting/tests/yolo_6/processed_static_data.parquet\n",
      "\n",
      "================ PROCESSING SUMMARY ================\n",
      "SUCCESS: Completed processing 19 of 20 basins\n",
      "WARNING: 1 basins excluded due to quality issues\n",
      "INFO: Created training dataset with 92772 samples\n",
      "INFO: Created validation dataset with 47502 samples\n",
      "INFO: Created test dataset with 47212 samples\n"
     ]
    }
   ],
   "source": [
    "region_time_series_base_dirs = {\n",
    "    \"CA\": \"/Users/cooper/Desktop/CaravanifyParquet/CA/post_processed/timeseries/csv/CA\",\n",
    "    \"USA\": \"/Users/cooper/Desktop/CaravanifyParquet/USA/post_processed/timeseries/csv/USA\",\n",
    "}\n",
    "\n",
    "region_static_attributes_base_dirs = {\n",
    "    \"CA\": \"/Users/cooper/Desktop/CaravanifyParquet/CA/post_processed/attributes/CA\",\n",
    "    \"USA\": \"/Users/cooper/Desktop/CaravanifyParquet/USA/post_processed/attributes/USA\",\n",
    "}\n",
    "\n",
    "datamodule = HydroLazyDataModule(\n",
    "    region_time_series_base_dirs=region_time_series_base_dirs,\n",
    "    region_static_attributes_base_dirs=region_static_attributes_base_dirs,\n",
    "    path_to_preprocessing_output_directory=\"/Users/cooper/Desktop/hydro-forecasting/tests/yolo_6\",\n",
    "    group_identifier=\"gauge_id\",\n",
    "    batch_size=2048,\n",
    "    input_length=70,\n",
    "    output_length=10,\n",
    "    forcing_features=forcing_features,\n",
    "    static_features=static_features,\n",
    "    target=\"streamflow\",\n",
    "    preprocessing_configs=preprocessing_config,\n",
    "    num_workers=4,\n",
    "    min_train_years=5,\n",
    "    train_prop=0.5,\n",
    "    val_prop=0.25,\n",
    "    test_prop=0.25,\n",
    "    max_imputation_gap_size=5,\n",
    "    list_of_gauge_ids_to_process=basin_ids,\n",
    "    is_autoregressive=True,\n",
    "    files_per_batch=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5525f5",
   "metadata": {},
   "source": [
    "## Let's try training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74eb05bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = datamodule.input_length\n",
    "output_length = datamodule.output_length\n",
    "\n",
    "config = TiDEConfig(\n",
    "    input_len=input_length,\n",
    "    output_len=output_length,\n",
    "    input_size=len(forcing_features),\n",
    "    future_input_size=len(forcing_features),\n",
    "    static_size=len(static_features),\n",
    "    num_encoder_layers=2,\n",
    "    num_decoder_layers=2,\n",
    "    decoder_output_size=16,\n",
    "    hidden_size=16,\n",
    "    temporal_decoder_hidden_size=16,\n",
    "    past_feature_projection_size=4,\n",
    "    future_forcing_projection_size=4,\n",
    "    use_layer_norm=True,\n",
    "    dropout=0.1,\n",
    "    learning_rate=1e-3,\n",
    ")\n",
    "\n",
    "# Instantiate the Lightning module.\n",
    "model = LitTiDE(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b384c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04f3d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
