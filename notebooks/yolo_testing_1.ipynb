{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9308b178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added /Users/cooper/Desktop/hydro-forecasting/src to Python path\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src directory to Python path\n",
    "project_root = Path.cwd().parent  \n",
    "src_path = project_root / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "    print(f\"Added {src_path} to Python path\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2caabe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydro_forecasting.data.lazy_datamodule import HydroLazyDataModule\n",
    "from hydro_forecasting.preprocessing.grouped import GroupedPipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from hydro_forecasting.preprocessing.standard_scale import StandardScaleTransformer\n",
    "from hydro_forecasting.data.caravanify_parquet import (\n",
    "    CaravanifyParquet,\n",
    "    CaravanifyParquetConfig,\n",
    ")\n",
    "\n",
    "from hydro_forecasting.models.tide import LitTiDE, TiDEConfig\n",
    "from hydro_forecasting.model_evaluation.evaluators import TSForecastEvaluator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a545d504",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0bd441f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_ca = CaravanifyParquetConfig(\n",
    "    attributes_dir=\"/Users/cooper/Desktop/CaravanifyParquet/CA/post_processed/attributes\",\n",
    "    timeseries_dir=\"/Users/cooper/Desktop/CaravanifyParquet/CA/post_processed/timeseries/csv\",\n",
    "    shapefile_dir=\"/Users/cooper/Desktop/CAMELS-CH/data/CARAVANIFY/CA/post_processed/shapefiles\",\n",
    "    gauge_id_prefix=\"CA\",\n",
    "    use_hydroatlas_attributes=True,\n",
    "    use_caravan_attributes=True,\n",
    "    use_other_attributes=True,\n",
    ")\n",
    "\n",
    "caravan_ca = CaravanifyParquet(config_ca)\n",
    "basin_ids = caravan_ca.get_all_gauge_ids()[:10]\n",
    "\n",
    "# basin_ids = [bid for bid in basin_ids if bid != \"CA_15030\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f1055a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_us = CaravanifyParquetConfig(\n",
    "    attributes_dir=\"/Users/cooper/Desktop/CaravanifyParquet/USA/post_processed/attributes\",\n",
    "    timeseries_dir=\"/Users/cooper/Desktop/CaravanifyParquet/USA/post_processed/timeseries/csv\",\n",
    "    shapefile_dir=\"/Users/cooper/Desktop/CAMELS-CH/data/CARAVANIFY/USA/post_processed/shapefiles\",\n",
    "    gauge_id_prefix=\"USA\",\n",
    "    use_hydroatlas_attributes=True,\n",
    "    use_caravan_attributes=True,\n",
    "    use_other_attributes=True,\n",
    ")\n",
    "\n",
    "caravan_us = CaravanifyParquet(config_us)\n",
    "basin_ids += caravan_us.get_all_gauge_ids()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10f3e392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CA_15013',\n",
       " 'CA_15016',\n",
       " 'CA_15020',\n",
       " 'CA_15022',\n",
       " 'CA_15025',\n",
       " 'CA_15030',\n",
       " 'CA_15034',\n",
       " 'CA_15039',\n",
       " 'CA_15040',\n",
       " 'CA_15044',\n",
       " 'USA_01013500',\n",
       " 'USA_01022500',\n",
       " 'USA_01030500',\n",
       " 'USA_01031500',\n",
       " 'USA_01047000',\n",
       " 'USA_01052500',\n",
       " 'USA_01054200',\n",
       " 'USA_01055000',\n",
       " 'USA_01057000',\n",
       " 'USA_01073000']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basin_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8755a7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "forcing_features = [\n",
    "    \"snow_depth_water_equivalent_mean\",\n",
    "    \"surface_net_solar_radiation_mean\",\n",
    "    \"surface_net_thermal_radiation_mean\",\n",
    "    \"potential_evaporation_sum_ERA5_LAND\",\n",
    "    \"potential_evaporation_sum_FAO_PENMAN_MONTEITH\",\n",
    "    \"temperature_2m_mean\",\n",
    "    \"temperature_2m_min\",\n",
    "    \"temperature_2m_max\",\n",
    "    \"total_precipitation_sum\",\n",
    "]\n",
    "\n",
    "static_features = [\n",
    "    # \"gauge_id\",\n",
    "    \"p_mean\",\n",
    "    \"area\",\n",
    "    \"ele_mt_sav\",\n",
    "    \"high_prec_dur\",\n",
    "    \"frac_snow\",\n",
    "    \"high_prec_freq\",\n",
    "    \"slp_dg_sav\",\n",
    "    \"cly_pc_sav\",\n",
    "    \"aridity_ERA5_LAND\",\n",
    "    \"aridity_FAO_PM\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b02753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_pipeline = GroupedPipeline(\n",
    "    Pipeline([(\"scaler\", StandardScaleTransformer())]),\n",
    "    columns=forcing_features,\n",
    "    group_identifier=\"gauge_id\",\n",
    ")\n",
    "\n",
    "target_pipeline = GroupedPipeline(\n",
    "    Pipeline([(\"scaler\", StandardScaleTransformer())]),\n",
    "    columns=[\"streamflow\"],\n",
    "    group_identifier=\"gauge_id\",\n",
    ")\n",
    "\n",
    "static_pipeline = Pipeline([(\"scaler\", StandardScaleTransformer())])\n",
    "\n",
    "preprocessing_config = {\n",
    "    \"features\": {\"pipeline\": feature_pipeline},\n",
    "    \"target\": {\"pipeline\": target_pipeline},\n",
    "    \"static_features\": {\"pipeline\": static_pipeline, \"columns\": static_features},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34197fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_time_series_base_dirs = {\n",
    "    \"CA\": \"/Users/cooper/Desktop/CaravanifyParquet/CA/post_processed/timeseries/csv/CA\",\n",
    "    \"USA\": \"/Users/cooper/Desktop/CaravanifyParquet/USA/post_processed/timeseries/csv/USA\",\n",
    "}\n",
    "\n",
    "region_static_attributes_base_dirs = {\n",
    "    \"CA\": \"/Users/cooper/Desktop/CaravanifyParquet/CA/post_processed/attributes/CA\",\n",
    "    \"USA\": \"/Users/cooper/Desktop/CaravanifyParquet/USA/post_processed/attributes/USA\",\n",
    "}\n",
    "\n",
    "datamodule = HydroLazyDataModule(\n",
    "    region_time_series_base_dirs=region_time_series_base_dirs,\n",
    "    region_static_attributes_base_dirs=region_static_attributes_base_dirs,\n",
    "    path_to_preprocessing_output_directory=\"/Users/cooper/Desktop/hydro-forecasting/tests/yolo_6\",\n",
    "    group_identifier=\"gauge_id\",\n",
    "    batch_size=2048,\n",
    "    input_length=70,\n",
    "    output_length=10,\n",
    "    forcing_features=forcing_features,\n",
    "    static_features=static_features,\n",
    "    target=\"streamflow\",\n",
    "    preprocessing_configs=preprocessing_config,\n",
    "    num_workers=4,\n",
    "    min_train_years=5,\n",
    "    train_prop=0.5,\n",
    "    val_prop=0.25,\n",
    "    test_prop=0.25,\n",
    "    max_imputation_gap_size=5,\n",
    "    list_of_gauge_ids_to_process=basin_ids,\n",
    "    is_autoregressive=True,\n",
    "    files_per_batch=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5525f5",
   "metadata": {},
   "source": [
    "## Let's try training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74eb05bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = datamodule.input_length\n",
    "output_length = datamodule.output_length\n",
    "\n",
    "config = TiDEConfig(\n",
    "    input_len=input_length,\n",
    "    output_len=output_length,\n",
    "    input_size=len(forcing_features),\n",
    "    future_input_size=len(forcing_features),\n",
    "    static_size=len(static_features),\n",
    "    num_encoder_layers=2,\n",
    "    num_decoder_layers=2,\n",
    "    decoder_output_size=16,\n",
    "    hidden_size=16,\n",
    "    temporal_decoder_hidden_size=16,\n",
    "    past_feature_projection_size=4,\n",
    "    future_forcing_projection_size=4,\n",
    "    use_layer_norm=True,\n",
    "    dropout=0.1,\n",
    "    learning_rate=1e-3,\n",
    ")\n",
    "\n",
    "# Instantiate the Lightning module.\n",
    "model = LitTiDE(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65b384c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ STARTING PREPROCESSING PIPELINE ================\n",
      "\n",
      "================ LOADING STATIC ATTRIBUTES ================\n",
      "INFO: Attempting to load static attributes for 20 gauge IDs\n",
      "INFO: Loaded static attributes for 20 unique basins from 6 files.\n",
      "INFO: Successfully loaded static attributes for 20 basins.\n",
      "\n",
      "================ FITTING PREPROCESSING PIPELINES ================\n",
      "INFO: Loading time series data for pipeline fitting...\n",
      "INFO: Loaded time series data for 20 basins\n",
      "INFO: Split time series data into train (96211), val (48099), test (48121)\n",
      "INFO: Fitted 3 pipelines\n",
      "\n",
      "================ PROCESSING BASIN TIME SERIES ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing basins: 100%|██████████| 20/20 [00:01<00:00, 18.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ PROCESSING STATIC ATTRIBUTES ================\n",
      "INFO: Processing static attributes...\n",
      "SUCCESS: Saved transformed static attributes for 19 basins to /Users/cooper/Desktop/hydro-forecasting/tests/yolo_6/processed_static_data.parquet\n",
      "\n",
      "================ PROCESSING SUMMARY ================\n",
      "SUCCESS: Completed processing 19 of 20 basins\n",
      "WARNING: 1 basins excluded due to quality issues\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type      | Params | Mode \n",
      "----------------------------------------------------\n",
      "0 | mse_criterion | MSELoss   | 0      | train\n",
      "1 | model         | TiDEModel | 22.5 K | train\n",
      "----------------------------------------------------\n",
      "22.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "22.5 K    Total params\n",
      "0.090     Total estimated model params size (MB)\n",
      "61        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Created training dataset with 92772 samples\n",
      "INFO: Created validation dataset with 47502 samples\n",
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (46) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 46/46 [00:08<00:00,  5.22it/s, v_num=9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 46/46 [00:08<00:00,  5.19it/s, v_num=9]\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e04f3d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_and_datamodules = {\n",
    "    \"TiDE\": (model, datamodule),\n",
    "}\n",
    "\n",
    "evaluator = TSForecastEvaluator(\n",
    "    horizons=list(range(1, output_length + 1)),\n",
    "    models_and_datamodules=models_and_datamodules,\n",
    "    trainer_kwargs={\n",
    "        \"accelerator\": \"gpu\",\n",
    "        \"devices\": 1,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10f5de30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing TiDE...\n",
      "\n",
      "================ STARTING PREPROCESSING PIPELINE ================\n",
      "\n",
      "================ LOADING STATIC ATTRIBUTES ================\n",
      "INFO: Attempting to load static attributes for 19 gauge IDs\n",
      "INFO: Loaded static attributes for 19 unique basins from 6 files.\n",
      "INFO: Successfully loaded static attributes for 19 basins.\n",
      "\n",
      "================ FITTING PREPROCESSING PIPELINES ================\n",
      "INFO: Loading time series data for pipeline fitting...\n",
      "INFO: Loaded time series data for 19 basins\n",
      "INFO: Split time series data into train (95566), val (47777), test (47797)\n",
      "INFO: Fitted 3 pipelines\n",
      "\n",
      "================ PROCESSING BASIN TIME SERIES ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing basins: 100%|██████████| 19/19 [00:01<00:00, 16.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ PROCESSING STATIC ATTRIBUTES ================\n",
      "INFO: Processing static attributes...\n",
      "SUCCESS: Saved transformed static attributes for 19 basins to /Users/cooper/Desktop/hydro-forecasting/tests/yolo_6/processed_static_data.parquet\n",
      "\n",
      "================ PROCESSING SUMMARY ================\n",
      "SUCCESS: Completed processing 19 of 19 basins\n",
      "INFO: Created test dataset with 47212 samples\n",
      "Testing DataLoader 0: 100%|██████████| 24/24 [00:02<00:00, 11.54it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss                   nan\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Evaluating results with shape: preds=(47212, 10), obs=(47212, 10), basin_ids=(47212,)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results = \u001b[43mevaluator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtest_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/src/hydro_forecasting/model_evaluation/evaluators.py:109\u001b[39m, in \u001b[36mTSForecastEvaluator.test_models\u001b[39m\u001b[34m(self, datamodule)\u001b[39m\n\u001b[32m    103\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    104\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt have test_results attribute. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    105\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mEnsure your LightningModule stores test outputs in self.test_results.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    106\u001b[39m         )\n\u001b[32m    108\u001b[39m     \u001b[38;5;66;03m# Extract and evaluate results\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     df, metrics, basin_metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtest_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_datamodule\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m     \u001b[38;5;28mself\u001b[39m.results[name] = {\n\u001b[32m    113\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdf\u001b[39m\u001b[33m\"\u001b[39m: df,\n\u001b[32m    114\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmetrics\u001b[39m\u001b[33m\"\u001b[39m: metrics,\n\u001b[32m    115\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbasin_metrics\u001b[39m\u001b[33m\"\u001b[39m: basin_metrics,\n\u001b[32m    116\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdatamodule\u001b[39m\u001b[33m\"\u001b[39m: model_datamodule,  \u001b[38;5;66;03m# Store reference to used datamodule\u001b[39;00m\n\u001b[32m    117\u001b[39m     }\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/src/hydro_forecasting/model_evaluation/evaluators.py:174\u001b[39m, in \u001b[36mTSForecastEvaluator.evaluate\u001b[39m\u001b[34m(self, test_results, datamodule)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    161\u001b[39m \u001b[33;03mEvaluate model test results and compute metrics.\u001b[39;00m\n\u001b[32m    162\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    171\u001b[39m \u001b[33;03m        - Dictionary with per-basin metrics by horizon\u001b[39;00m\n\u001b[32m    172\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    173\u001b[39m \u001b[38;5;66;03m# Create evaluation dataframe from test results\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m df = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_evaluation_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;66;03m# Calculate overall metrics for each horizon\u001b[39;00m\n\u001b[32m    177\u001b[39m overall_metrics = \u001b[38;5;28mself\u001b[39m._calculate_overall_metrics(df)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/src/hydro_forecasting/model_evaluation/evaluators.py:268\u001b[39m, in \u001b[36mTSForecastEvaluator._prepare_evaluation_dataframe\u001b[39m\u001b[34m(self, test_results, datamodule)\u001b[39m\n\u001b[32m    266\u001b[39m dates_expanded = []\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, input_date \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_end_dates):\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m     input_date_dt = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    269\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m horizon \u001b[38;5;129;01min\u001b[39;00m current_horizons:\n\u001b[32m    270\u001b[39m         \u001b[38;5;66;03m# Calculate forecast date by adding horizon days to input end date\u001b[39;00m\n\u001b[32m    271\u001b[39m         forecast_date = input_date_dt + pd.Timedelta(days=horizon)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/pandas/core/tools/datetimes.py:1101\u001b[39m, in \u001b[36mto_datetime\u001b[39m\u001b[34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[39m\n\u001b[32m   1099\u001b[39m         result = convert_listlike(argc, \u001b[38;5;28mformat\u001b[39m)\n\u001b[32m   1100\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1101\u001b[39m     result = convert_listlike(\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43marg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mformat\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m   1102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, np.bool_):\n\u001b[32m   1103\u001b[39m         result = \u001b[38;5;28mbool\u001b[39m(result)  \u001b[38;5;66;03m# TODO: avoid this kludge.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/torch/_tensor.py:1194\u001b[39m, in \u001b[36mTensor.__array__\u001b[39m\u001b[34m(self, dtype)\u001b[39m\n\u001b[32m   1192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor.__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype=dtype)\n\u001b[32m   1193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1194\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.numpy().astype(dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mTypeError\u001b[39m: can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "results = evaluator.test_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350c5fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
