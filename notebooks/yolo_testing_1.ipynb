{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9308b178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added /Users/cooper/Desktop/hydro-forecasting/src to Python path\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src directory to Python path\n",
    "project_root = Path.cwd().parent  \n",
    "src_path = project_root / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "    print(f\"Added {src_path} to Python path\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2caabe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydro_forecasting.data.lazy_datamodule import HydroLazyDataModule\n",
    "from hydro_forecasting.preprocessing.grouped import GroupedPipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from hydro_forecasting.preprocessing.standard_scale import StandardScaleTransformer\n",
    "from hydro_forecasting.data.caravanify_parquet import (\n",
    "    CaravanifyParquet,\n",
    "    CaravanifyParquetConfig,\n",
    ")\n",
    "\n",
    "from hydro_forecasting.models.tide import LitTiDE, TiDEConfig\n",
    "from hydro_forecasting.model_evaluation.hp_from_yaml import hp_from_yaml\n",
    "\n",
    "from hydro_forecasting.model_evaluation.evaluators import TSForecastEvaluator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a545d504",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0df5d83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decoder_output_size': 24,\n",
       " 'dropout': 0.4040330172235821,\n",
       " 'future_forcing_projection_size': 0,\n",
       " 'future_input_size': 9,\n",
       " 'group_identifier': 'gauge_id',\n",
       " 'hidden_size': 110,\n",
       " 'input_len': 34,\n",
       " 'input_size': 10,\n",
       " 'learning_rate': 0.00029399848560567596,\n",
       " 'num_decoder_layers': 2,\n",
       " 'num_encoder_layers': 2,\n",
       " 'output_len': 10,\n",
       " 'past_feature_projection_size': 0,\n",
       " 'scheduler_factor': 0.5,\n",
       " 'scheduler_patience': 5,\n",
       " 'static_size': 10,\n",
       " 'temporal_decoder_hidden_size': 51,\n",
       " 'use_layer_norm': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yaml_path = Path(\"/Users/cooper/Desktop/hydro-forecasting/notebooks/tide.yaml\")\n",
    "\n",
    "tide_hp = hp_from_yaml(\"tide\", yaml_path)\n",
    "tide_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0bd441f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_ca = CaravanifyParquetConfig(\n",
    "    attributes_dir=\"/Users/cooper/Desktop/CaravanifyParquet/CA/post_processed/attributes\",\n",
    "    timeseries_dir=\"/Users/cooper/Desktop/CaravanifyParquet/CA/post_processed/timeseries/csv\",\n",
    "    shapefile_dir=\"/Users/cooper/Desktop/CAMELS-CH/data/CARAVANIFY/CA/post_processed/shapefiles\",\n",
    "    gauge_id_prefix=\"CA\",\n",
    "    use_hydroatlas_attributes=True,\n",
    "    use_caravan_attributes=True,\n",
    "    use_other_attributes=True,\n",
    ")\n",
    "\n",
    "caravan_ca = CaravanifyParquet(config_ca)\n",
    "basin_ids = caravan_ca.get_all_gauge_ids()[:10]\n",
    "\n",
    "# basin_ids = [bid for bid in basin_ids if bid != \"CA_15030\"]\n",
    "\n",
    "caravan_ca.load_stations(basin_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f1055a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_us = CaravanifyParquetConfig(\n",
    "    attributes_dir=\"/Users/cooper/Desktop/CaravanifyParquet/USA/post_processed/attributes\",\n",
    "    timeseries_dir=\"/Users/cooper/Desktop/CaravanifyParquet/USA/post_processed/timeseries/csv\",\n",
    "    shapefile_dir=\"/Users/cooper/Desktop/CAMELS-CH/data/CARAVANIFY/USA/post_processed/shapefiles\",\n",
    "    gauge_id_prefix=\"USA\",\n",
    "    use_hydroatlas_attributes=True,\n",
    "    use_caravan_attributes=True,\n",
    "    use_other_attributes=True,\n",
    ")\n",
    "\n",
    "caravan_us = CaravanifyParquet(config_us)\n",
    "basin_ids += caravan_us.get_all_gauge_ids()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8755a7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "forcing_features = [\n",
    "    \"snow_depth_water_equivalent_mean\",\n",
    "    \"surface_net_solar_radiation_mean\",\n",
    "    \"surface_net_thermal_radiation_mean\",\n",
    "    \"potential_evaporation_sum_ERA5_LAND\",\n",
    "    \"potential_evaporation_sum_FAO_PENMAN_MONTEITH\",\n",
    "    \"temperature_2m_mean\",\n",
    "    \"temperature_2m_min\",\n",
    "    \"temperature_2m_max\",\n",
    "    \"total_precipitation_sum\",\n",
    "]\n",
    "\n",
    "static_features = [\n",
    "    # \"gauge_id\",\n",
    "    \"p_mean\",\n",
    "    \"area\",\n",
    "    \"ele_mt_sav\",\n",
    "    \"high_prec_dur\",\n",
    "    \"frac_snow\",\n",
    "    \"high_prec_freq\",\n",
    "    \"slp_dg_sav\",\n",
    "    \"cly_pc_sav\",\n",
    "    \"aridity_ERA5_LAND\",\n",
    "    \"aridity_FAO_PM\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b02753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_pipeline = GroupedPipeline(\n",
    "    Pipeline([(\"scaler\", StandardScaleTransformer())]),\n",
    "    columns=forcing_features,\n",
    "    group_identifier=\"gauge_id\",\n",
    ")\n",
    "\n",
    "target_pipeline = GroupedPipeline(\n",
    "    Pipeline([(\"scaler\", StandardScaleTransformer())]),\n",
    "    columns=[\"streamflow\"],\n",
    "    group_identifier=\"gauge_id\",\n",
    ")\n",
    "\n",
    "static_pipeline = Pipeline([(\"scaler\", StandardScaleTransformer())])\n",
    "\n",
    "preprocessing_config = {\n",
    "    \"features\": {\"pipeline\": feature_pipeline},\n",
    "    \"target\": {\"pipeline\": target_pipeline},\n",
    "    \"static_features\": {\"pipeline\": static_pipeline, \"columns\": static_features},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34197fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Starting data preparation...\n",
      "INFO: No reusable data found or reuse failed. Reason: Error checking for existing processed data: LoadedData.__init__() got an unexpected keyword argument 'quality_report'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cooper/Desktop/hydro-forecasting/src/hydro_forecasting/data/lazy_datamodule.py\", line 575, in _check_and_reuse_existing_processed_data\n",
      "    loaded_data = LoadedData(\n",
      "                  ^^^^^^^^^^^\n",
      "TypeError: LoadedData.__init__() got an unexpected keyword argument 'quality_report'\n",
      ". Running preprocessing...\n",
      "INFO: Generated Run UUID: 5af0c3ea-c280-59e5-83f0-bcf41247b3ab\n",
      "SUCCESS: Config saved to /Users/cooper/Desktop/hydro-forecasting/tests/yolo_6/5af0c3ea-c280-59e5-83f0-bcf41247b3ab/config.json\n",
      "SUCCESS: Static features saved to /Users/cooper/Desktop/hydro-forecasting/tests/yolo_6/5af0c3ea-c280-59e5-83f0-bcf41247b3ab/processed_static_features.parquet\n",
      "SUCCESS: Static features pipeline saved to /Users/cooper/Desktop/hydro-forecasting/tests/yolo_6/5af0c3ea-c280-59e5-83f0-bcf41247b3ab/fitted_static_pipeline.joblib\n",
      "INFO: Processed 20 basins, 19 passed quality checks\n",
      "SUCCESS: Preprocessing completed successfully. Output at /Users/cooper/Desktop/hydro-forecasting/tests/yolo_6/5af0c3ea-c280-59e5-83f0-bcf41247b3ab\n",
      "INFO: Hydro processor completed successfully.\n",
      "INFO: Loading fitted pipelines...\n",
      "INFO: Loaded 2 time series pipelines.\n",
      "INFO: Loaded static features pipeline.\n",
      "INFO: 19 basins retained after processing.\n",
      "INFO: Creating index entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating index entries: 100%|██████████| 1/1 [00:00<00:00, 1795.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Index entries created successfully at /Users/cooper/Desktop/hydro-forecasting/tests/yolo_6/5af0c3ea-c280-59e5-83f0-bcf41247b3ab/index.\n",
      "INFO: Data preparation finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'HydroLazyDataModule' object has no attribute 'train_index_meta_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     11\u001b[39m datamodule = HydroLazyDataModule(\n\u001b[32m     12\u001b[39m     region_time_series_base_dirs=region_time_series_base_dirs,\n\u001b[32m     13\u001b[39m     region_static_attributes_base_dirs=region_static_attributes_base_dirs,\n\u001b[32m   (...)\u001b[39m\u001b[32m     31\u001b[39m     files_per_batch=\u001b[32m20\u001b[39m,\n\u001b[32m     32\u001b[39m )\n\u001b[32m     34\u001b[39m datamodule.prepare_data()\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[43mdatamodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hydro-forecasting/src/hydro_forecasting/data/lazy_datamodule.py:844\u001b[39m, in \u001b[36mHydroLazyDataModule.setup\u001b[39m\u001b[34m(self, stage)\u001b[39m\n\u001b[32m    829\u001b[39m common_args = {\n\u001b[32m    830\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.target,\n\u001b[32m    831\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mforcing_features\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.forcing_features,\n\u001b[32m   (...)\u001b[39m\u001b[32m    838\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mis_autoregressive\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.is_autoregressive,\n\u001b[32m    839\u001b[39m }\n\u001b[32m    841\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stage == \u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m stage \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    842\u001b[39m     \u001b[38;5;28mself\u001b[39m.train_dataset = HydroLazyDataset(\n\u001b[32m    843\u001b[39m         index_file_path=\u001b[38;5;28mself\u001b[39m.train_index_path,\n\u001b[32m--> \u001b[39m\u001b[32m844\u001b[39m         index_meta_file_path=\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_index_meta_path\u001b[49m,\n\u001b[32m    845\u001b[39m         **common_args,\n\u001b[32m    846\u001b[39m     )\n\u001b[32m    847\u001b[39m     \u001b[38;5;28mself\u001b[39m.val_dataset = HydroLazyDataset(\n\u001b[32m    848\u001b[39m         index_file_path=\u001b[38;5;28mself\u001b[39m.val_index_path,\n\u001b[32m    849\u001b[39m         index_meta_file_path=\u001b[38;5;28mself\u001b[39m.val_index_meta_path,\n\u001b[32m    850\u001b[39m         **common_args,\n\u001b[32m    851\u001b[39m     )\n\u001b[32m    852\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    853\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mINFO: Created training dataset with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.train_dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m samples\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    854\u001b[39m     )\n",
      "\u001b[31mAttributeError\u001b[39m: 'HydroLazyDataModule' object has no attribute 'train_index_meta_path'"
     ]
    }
   ],
   "source": [
    "region_time_series_base_dirs = {\n",
    "    \"CA\": \"/Users/cooper/Desktop/CaravanifyParquet/CA/post_processed/timeseries/csv/CA\",\n",
    "    \"USA\": \"/Users/cooper/Desktop/CaravanifyParquet/USA/post_processed/timeseries/csv/USA\",\n",
    "}\n",
    "\n",
    "region_static_attributes_base_dirs = {\n",
    "    \"CA\": \"/Users/cooper/Desktop/CaravanifyParquet/CA/post_processed/attributes/CA\",\n",
    "    \"USA\": \"/Users/cooper/Desktop/CaravanifyParquet/USA/post_processed/attributes/USA\",\n",
    "}\n",
    "\n",
    "datamodule = HydroLazyDataModule(\n",
    "    region_time_series_base_dirs=region_time_series_base_dirs,\n",
    "    region_static_attributes_base_dirs=region_static_attributes_base_dirs,\n",
    "    path_to_preprocessing_output_directory=\"/Users/cooper/Desktop/hydro-forecasting/tests/yolo_6\",\n",
    "    group_identifier=\"gauge_id\",\n",
    "    batch_size=2048,\n",
    "    input_length=tide_hp[\"input_len\"],\n",
    "    output_length=tide_hp[\"output_len\"],\n",
    "    forcing_features=forcing_features,\n",
    "    static_features=static_features,\n",
    "    target=\"streamflow\",\n",
    "    preprocessing_configs=preprocessing_config,\n",
    "    num_workers=4,\n",
    "    min_train_years=5,\n",
    "    train_prop=0.5,\n",
    "    val_prop=0.25,\n",
    "    test_prop=0.25,\n",
    "    max_imputation_gap_size=5,\n",
    "    list_of_gauge_ids_to_process=basin_ids,\n",
    "    is_autoregressive=True,\n",
    "    files_per_batch=20,\n",
    ")\n",
    "\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0939b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pympler import asizeof  # Import asizeof\n",
    "\n",
    "ie = datamodule.val_index_path\n",
    "\n",
    "# Calculate size using pympler.asizeof\n",
    "size_ie_mb = asizeof.asizeof(ie) / (1024 * 1024)\n",
    "print(f\"Approximate deep size of index entries in memory: {size_ie_mb:.2f} MB\")\n",
    "\n",
    "# Calculate size using pympler.asizeof\n",
    "size_datamodule_mb = asizeof.asizeof(datamodule) / (1024 * 1024)\n",
    "print(f\"Approximate deep size of datamodule in memory: {size_datamodule_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76623ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.index_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc06754",
   "metadata": {},
   "source": [
    "## Verify static data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a807898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = datamodule.test_dataset\n",
    "# if not test_dataset:\n",
    "#     print(\"Test dataset not found.\")\n",
    "# elif len(test_dataset) == 0:\n",
    "#     print(\"Test dataset is empty.\")\n",
    "# else:\n",
    "#     print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "#     # --- Get a Sample ---\n",
    "#     sample_index = 1654\n",
    "#     print(f\"Getting sample at index {sample_index}...\")\n",
    "#     try:\n",
    "#         sample = test_dataset[sample_index]\n",
    "\n",
    "#         # --- Check for NaNs in the Sample Tensors ---\n",
    "#         print(\"\\n--- Checking for NaNs in sample tensors ---\")\n",
    "#         for key, tensor in sample.items():\n",
    "#             if isinstance(tensor, torch.Tensor):\n",
    "#                 has_nan = torch.isnan(tensor).any().item()\n",
    "#                 print(f\"Tensor'{key}' shape: {tensor.shape}, Contains NaNs: {has_nan}\")\n",
    "#                 print(f\"  Sample tensor '{key}': {tensor[:5]}\")\n",
    "#                 if has_nan:\n",
    "#                     # Optional: Print where NaNs occur\n",
    "#                     nan_indices = torch.nonzero(torch.isnan(tensor))\n",
    "#                     print(f\"  NaN indices in '{key}': {nan_indices.tolist()[:5]}...\") # Print first 5\n",
    "#             else:\n",
    "#                 print(f\"Item '{key}' is not a tensor (type: {type(tensor)})\")\n",
    "\n",
    "#     except IndexError:\n",
    "#         print(f\"Error: Index {sample_index} out of bounds for dataset size {len(test_dataset)}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred while getting or checking the sample: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bea655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ie = datamodule.val_index_entries[1661]\n",
    "\n",
    "# file_path = ie[\"file_path\"]\n",
    "# start_idx = ie[\"start_idx\"]\n",
    "# end_idx = ie[\"end_idx\"]\n",
    "# gauge_id = ie[\"gauge_id\"]\n",
    "\n",
    "# data = pd.read_parquet(file_path)\n",
    "\n",
    "# # Slice the data\n",
    "# data_slice = data.iloc[start_idx:end_idx]\n",
    "# print(f\"Data slice shape: {data_slice.shape}\")\n",
    "\n",
    "# data_slice[\"streamflow\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5525f5",
   "metadata": {},
   "source": [
    "## Let's try training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eb05bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = datamodule.input_length\n",
    "output_length = datamodule.output_length\n",
    "\n",
    "config = TiDEConfig(**tide_hp)\n",
    "\n",
    "\n",
    "# Instantiate the Lightning module.\n",
    "model = LitTiDE(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b384c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=5,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04f3d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_and_datamodules = {\n",
    "    \"TiDE\": (model, datamodule),\n",
    "}\n",
    "\n",
    "evaluator = TSForecastEvaluator(\n",
    "    horizons=list(range(1, output_length + 1)),\n",
    "    models_and_datamodules=models_and_datamodules,\n",
    "    trainer_kwargs={\n",
    "        \"accelerator\": \"cpu\",\n",
    "        \"devices\": 1,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f5de30",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluator.test_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f23c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = results[\"TiDE\"][\"df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dcd14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8f78d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "\n",
    "basin_id = \"CA_15013\"\n",
    "df_basin = df[df[\"basin_id\"] == basin_id]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_basin[\"date\"], df_basin[\"prediction\"], label=\"Prediction\", color=\"blue\")\n",
    "plt.plot(df_basin[\"date\"], df_basin[\"observed\"], label=\"Observed\", color=\"orange\")\n",
    "plt.title(f\"Observed vs Prediction for {basin_id}\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Streamflow\")\n",
    "plt.legend()\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m\"))\n",
    "plt.gcf().autofmt_xdate()\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75872aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e45c91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
