{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c98b4b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from hydro_forecasting.data.caravanify_parquet import (\n",
    "    CaravanifyParquet,\n",
    "    CaravanifyParquetConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bdfe92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 11 clusters...\n",
      "Processing cluster 0...\n",
      "  - Loading 5 stations for CL\n",
      "  - Loading 54 stations for USA\n",
      "  - Loading 83 stations for camelsbr\n",
      "  - Loading 1012 stations for hysets\n",
      "  - Loading 24 stations for lamah\n",
      "  - Added 1178 stations to cluster 0\n",
      "Processing cluster 1...\n",
      "  - Loading 34 stations for CH\n",
      "  - Loading 45 stations for CL\n",
      "  - Loading 233 stations for USA\n",
      "  - Loading 51 stations for camelsaus\n",
      "  - Loading 42 stations for camelsgb\n",
      "  - Loading 40 stations for camelsbr\n",
      "  - Loading 3092 stations for hysets\n",
      "  - Loading 132 stations for lamah\n",
      "  - Added 3669 stations to cluster 1\n",
      "Processing cluster 2...\n",
      "  - Loading 53 stations for CH\n",
      "  - Loading 59 stations for CL\n",
      "  - Loading 75 stations for USA\n",
      "  - Loading 27 stations for camelsbr\n",
      "  - Loading 1536 stations for hysets\n",
      "  - Loading 164 stations for lamah\n",
      "  - Added 1914 stations to cluster 2\n",
      "Processing cluster 3...\n",
      "  - Loading 9 stations for CH\n",
      "  - Loading 187 stations for CL\n",
      "  - Loading 56 stations for USA\n",
      "  - Loading 11 stations for camelsaus\n",
      "  - Loading 624 stations for camelsgb\n",
      "  - Loading 61 stations for camelsbr\n",
      "  - Loading 779 stations for hysets\n",
      "  - Loading 27 stations for lamah\n",
      "  - Added 1754 stations to cluster 3\n",
      "Processing cluster 4...\n",
      "  - Loading 11 stations for CL\n",
      "  - Loading 14 stations for USA\n",
      "  - Loading 6 stations for camelsaus\n",
      "  - Loading 3 stations for camelsbr\n",
      "  - Loading 566 stations for hysets\n",
      "  - Loading 20 stations for lamah\n",
      "  - Added 620 stations to cluster 4\n",
      "Processing cluster 5...\n",
      "  - Loading 33 stations for CL\n",
      "  - Loading 62 stations for USA\n",
      "  - Loading 62 stations for camelsaus\n",
      "  - Loading 2 stations for camelsgb\n",
      "  - Loading 1 stations for camelsbr\n",
      "  - Loading 1266 stations for hysets\n",
      "  - Loading 54 stations for lamah\n",
      "  - Added 1480 stations to cluster 5\n",
      "Processing cluster 6...\n",
      "  - Loading 18 stations for CH\n",
      "  - Loading 36 stations for CL\n",
      "  - Loading 68 stations for USA\n",
      "  - Loading 1323 stations for hysets\n",
      "  - Loading 124 stations for lamah\n",
      "  - Added 1569 stations to cluster 6\n",
      "Processing cluster 7...\n",
      "  - Loading 16 stations for CH\n",
      "  - Loading 44 stations for CL\n",
      "  - Loading 7 stations for USA\n",
      "  - Loading 34 stations for camelsaus\n",
      "  - Loading 506 stations for camelsbr\n",
      "  - Loading 315 stations for hysets\n",
      "  - Loading 93 stations for lamah\n",
      "  - Added 1015 stations to cluster 7\n",
      "Processing cluster 8...\n",
      "  - Loading 2 stations for CH\n",
      "  - Loading 43 stations for CL\n",
      "  - Loading 63 stations for USA\n",
      "  - Loading 2 stations for camelsaus\n",
      "  - Loading 2 stations for camelsgb\n",
      "  - Loading 6 stations for camelsbr\n",
      "  - Loading 1033 stations for hysets\n",
      "  - Loading 18 stations for lamah\n",
      "  - Added 1169 stations to cluster 8\n",
      "Processing cluster 9...\n",
      "  - Loading 38 stations for CL\n",
      "  - Loading 12 stations for USA\n",
      "  - Loading 56 stations for camelsaus\n",
      "  - Loading 132 stations for camelsbr\n",
      "  - Loading 391 stations for hysets\n",
      "  - Loading 17 stations for lamah\n",
      "  - Added 646 stations to cluster 9\n",
      "Processing cluster 10...\n",
      "  - Loading 3 stations for CH\n",
      "  - Loading 1 stations for CL\n",
      "  - Loading 27 stations for USA\n",
      "  - Loading 1 stations for camelsgb\n",
      "  - Loading 11 stations for camelsbr\n",
      "  - Loading 810 stations for hysets\n",
      "  - Loading 186 stations for lamah\n",
      "  - Added 1039 stations to cluster 10\n",
      "\n",
      "Total stations processed: 16053\n",
      "\n",
      "Cluster Statistics:\n",
      "==================================================\n",
      "                     p_mean          pet_mean_FAO_PM           frac_snow  \\\n",
      "0   1012.7 ± 364.5 (n=1178)   719.7 ± 156.9 (n=1178)  0.2 ± 0.1 (n=1178)   \n",
      "1   1178.2 ± 225.9 (n=3669)   848.1 ± 145.9 (n=3669)  0.1 ± 0.1 (n=3669)   \n",
      "2    910.5 ± 423.2 (n=1914)   688.9 ± 220.9 (n=1914)  0.4 ± 0.2 (n=1914)   \n",
      "3   1343.0 ± 549.0 (n=1754)   699.3 ± 228.7 (n=1754)  0.0 ± 0.1 (n=1754)   \n",
      "4     977.3 ± 374.8 (n=620)   1026.4 ± 218.7 (n=620)   0.1 ± 0.1 (n=620)   \n",
      "5    898.1 ± 395.5 (n=1480)  1005.7 ± 153.7 (n=1480)  0.0 ± 0.1 (n=1480)   \n",
      "6    885.7 ± 356.9 (n=1569)   756.3 ± 189.9 (n=1569)  0.3 ± 0.2 (n=1569)   \n",
      "7   1244.6 ± 568.3 (n=1015)   965.3 ± 386.1 (n=1015)  0.1 ± 0.2 (n=1015)   \n",
      "8   1151.3 ± 363.7 (n=1169)   883.7 ± 161.1 (n=1169)  0.1 ± 0.2 (n=1169)   \n",
      "9     972.3 ± 493.7 (n=646)   1229.4 ± 274.8 (n=646)   0.0 ± 0.1 (n=646)   \n",
      "10   914.0 ± 311.0 (n=1039)   795.8 ± 157.5 (n=1039)  0.2 ± 0.1 (n=1039)   \n",
      "\n",
      "        aridity_FAO_PM  seasonality_FAO_PM                        area  \\\n",
      "0   0.8 ± 0.4 (n=1178)  1.1 ± 0.3 (n=1178)    1644.3 ± 8842.8 (n=1178)   \n",
      "1   0.8 ± 0.3 (n=3669)  1.1 ± 0.3 (n=3669)    1260.2 ± 5291.9 (n=3669)   \n",
      "2   0.9 ± 0.5 (n=1914)  1.2 ± 0.4 (n=1914)   3249.8 ± 14052.7 (n=1914)   \n",
      "3   0.6 ± 0.6 (n=1754)  1.3 ± 0.4 (n=1754)  8013.7 ± 149006.2 (n=1754)   \n",
      "4    1.3 ± 0.9 (n=620)   1.0 ± 0.2 (n=620)     1074.8 ± 7219.3 (n=620)   \n",
      "5   1.5 ± 0.9 (n=1480)  1.3 ± 0.3 (n=1480)    1107.4 ± 5942.4 (n=1480)   \n",
      "6   1.0 ± 0.5 (n=1569)  1.3 ± 0.4 (n=1569)   2158.5 ± 10009.4 (n=1569)   \n",
      "7   1.0 ± 0.8 (n=1015)  1.1 ± 0.4 (n=1015)  11962.8 ± 48136.1 (n=1015)   \n",
      "8   0.9 ± 0.4 (n=1169)  1.2 ± 0.3 (n=1169)    1405.0 ± 6933.1 (n=1169)   \n",
      "9    1.8 ± 1.5 (n=646)   1.1 ± 0.4 (n=646)  22410.7 ± 110030.4 (n=646)   \n",
      "10  1.0 ± 0.5 (n=1039)  1.1 ± 0.2 (n=1039)    1504.7 ± 5149.5 (n=1039)   \n",
      "\n",
      "                 ele_mt_sav  number_of_stations  \n",
      "0    595.8 ± 545.1 (n=1178)                1178  \n",
      "1    399.5 ± 377.5 (n=3669)                3669  \n",
      "2   1803.2 ± 926.4 (n=1914)                1914  \n",
      "3    416.4 ± 426.4 (n=1754)                1754  \n",
      "4     487.9 ± 596.3 (n=620)                 620  \n",
      "5    515.0 ± 532.9 (n=1480)                1480  \n",
      "6   1350.3 ± 846.7 (n=1569)                1569  \n",
      "7   1092.6 ± 748.7 (n=1015)                1015  \n",
      "8    616.6 ± 592.9 (n=1169)                1169  \n",
      "9    843.1 ± 1027.3 (n=646)                 646  \n",
      "10   536.9 ± 440.5 (n=1039)                1039  \n",
      "\n",
      "Results saved to 'cluster_statistics.csv' and 'cluster_detailed_data.csv'\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_CLUSTER_ASSIGNED = Path(\n",
    "    \"/Users/cooper/Desktop/hydro-forecasting/scripts/cluster_basins/clustering_results/cluster_assignments_shifted_refactor.csv\"\n",
    ")\n",
    "\n",
    "df = pd.read_csv(PATH_TO_CLUSTER_ASSIGNED)\n",
    "\n",
    "\n",
    "def get_ids_for_cluster(df, cluster_id):\n",
    "    \"\"\"Get the gauge_ids for a given cluster id\"\"\"\n",
    "    return df[df[\"cluster\"] == cluster_id][\"gauge_id\"].tolist()\n",
    "\n",
    "\n",
    "def filter_ids_by_country(ids, country_prefix):\n",
    "    \"\"\"Returns the ids that start with the given country prefix\"\"\"\n",
    "    return [gauge_id for gauge_id in ids if gauge_id.startswith(country_prefix)]\n",
    "\n",
    "\n",
    "# Define countries and static attributes of interest\n",
    "countries = [\"CH\", \"CL\", \"USA\", \"camelsaus\", \"camelsgb\", \"camelsbr\", \"hysets\", \"lamah\"]\n",
    "statics_of_interest = [\n",
    "    \"gauge_id\",  # Important: include gauge_id for filtering\n",
    "    \"p_mean\",\n",
    "    \"pet_mean_FAO_PM\",\n",
    "    \"frac_snow\",\n",
    "    \"aridity_FAO_PM\",\n",
    "    \"seasonality_FAO_PM\",\n",
    "    \"area\",\n",
    "    \"ele_mt_sav\",\n",
    "]\n",
    "\n",
    "# Create configurations for all countries\n",
    "configs = {}\n",
    "for country in countries:\n",
    "    configs[country] = CaravanifyParquetConfig(\n",
    "        attributes_dir=f\"/Users/cooper/Desktop/CaravanifyParquet/{country}/post_processed/attributes\",\n",
    "        timeseries_dir=f\"/Users/cooper/Desktop/CaravanifyParquet/{country}/post_processed/timeseries/csv\",\n",
    "        shapefile_dir=f\"/Users/cooper/Desktop/CaravanifyParquet/{country}/post_processed/shapefiles\",\n",
    "        gauge_id_prefix=country,\n",
    "        use_hydroatlas_attributes=True,\n",
    "        use_caravan_attributes=True,\n",
    "        use_other_attributes=True,\n",
    "    )\n",
    "\n",
    "# Process all clusters\n",
    "clusters = sorted(df[\"cluster\"].unique())\n",
    "all_clusters_data = []\n",
    "\n",
    "print(f\"Processing {len(clusters)} clusters...\")\n",
    "\n",
    "for cluster in clusters:\n",
    "    print(f\"Processing cluster {cluster}...\")\n",
    "\n",
    "    # Get all gauge_ids for this cluster\n",
    "    cluster_gauge_ids = get_ids_for_cluster(df, cluster)\n",
    "    cluster_static_dfs = []\n",
    "\n",
    "    # Process each country\n",
    "    for country in countries:\n",
    "        # Filter gauge_ids for this country\n",
    "        country_gauge_ids = filter_ids_by_country(cluster_gauge_ids, country)\n",
    "\n",
    "        if len(country_gauge_ids) == 0:\n",
    "            continue\n",
    "\n",
    "        print(f\"  - Loading {len(country_gauge_ids)} stations for {country}\")\n",
    "\n",
    "        try:\n",
    "            # Create CaravanifyParquet instance for this country\n",
    "            caravan = CaravanifyParquet(configs[country])\n",
    "\n",
    "            # Load static attributes for this country's gauge_ids\n",
    "            caravan._load_static_attributes(country_gauge_ids)\n",
    "            country_static = caravan.get_static_attributes()\n",
    "\n",
    "            if country_static.empty:\n",
    "                print(f\"    Warning: No static attributes found for {country}\")\n",
    "                continue\n",
    "\n",
    "            # Filter to only include the attributes we're interested in\n",
    "            available_attrs = [attr for attr in statics_of_interest if attr in country_static.columns]\n",
    "            missing_attrs = [attr for attr in statics_of_interest if attr not in country_static.columns]\n",
    "\n",
    "            if missing_attrs:\n",
    "                print(f\"    Warning: Missing attributes for {country}: {missing_attrs}\")\n",
    "\n",
    "            if available_attrs:\n",
    "                country_static_filtered = country_static[available_attrs].copy()\n",
    "                cluster_static_dfs.append(country_static_filtered)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"    Error loading data for {country}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Combine all country static data for this cluster\n",
    "    if cluster_static_dfs:\n",
    "        cluster_static = pd.concat(cluster_static_dfs, axis=0, ignore_index=True)\n",
    "\n",
    "        # Add cluster information\n",
    "        cluster_static[\"cluster\"] = cluster\n",
    "\n",
    "        # Apply unit conversions (daily to annual)\n",
    "        if \"p_mean\" in cluster_static.columns:\n",
    "            cluster_static[\"p_mean\"] = cluster_static[\"p_mean\"] * 365\n",
    "        if \"pet_mean_FAO_PM\" in cluster_static.columns:\n",
    "            cluster_static[\"pet_mean_FAO_PM\"] = cluster_static[\"pet_mean_FAO_PM\"] * 365\n",
    "\n",
    "        all_clusters_data.append(cluster_static)\n",
    "        print(f\"  - Added {len(cluster_static)} stations to cluster {cluster}\")\n",
    "    else:\n",
    "        print(f\"  - No data found for cluster {cluster}\")\n",
    "\n",
    "# Combine all cluster data\n",
    "if all_clusters_data:\n",
    "    combined_df = pd.concat(all_clusters_data, axis=0, ignore_index=True)\n",
    "    print(f\"\\nTotal stations processed: {len(combined_df)}\")\n",
    "\n",
    "    # Calculate cluster statistics\n",
    "    results = pd.DataFrame(index=sorted(combined_df[\"cluster\"].unique()))\n",
    "\n",
    "    # Calculate statistics for each attribute (excluding gauge_id and cluster)\n",
    "    numeric_attrs = [attr for attr in statics_of_interest if attr not in [\"gauge_id\", \"cluster\"]]\n",
    "\n",
    "    for attr in numeric_attrs:\n",
    "        if attr in combined_df.columns:\n",
    "            stats = combined_df.groupby(\"cluster\")[attr].agg([\"mean\", \"std\", \"count\"])\n",
    "            formatted_stats = stats.apply(\n",
    "                lambda row: f\"{row['mean']:.1f} ± {row['std']:.1f} (n={int(row['count'])})\", axis=1\n",
    "            )\n",
    "            results[attr] = formatted_stats\n",
    "        else:\n",
    "            print(f\"Warning: Attribute {attr} not found in combined data\")\n",
    "\n",
    "    # Add number of stations column\n",
    "    station_counts = combined_df.groupby(\"cluster\").size()\n",
    "    results[\"number_of_stations\"] = station_counts\n",
    "\n",
    "    print(\"\\nCluster Statistics:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(results)\n",
    "\n",
    "    # Save results\n",
    "    results.to_csv(\"cluster_statistics.csv\")\n",
    "    combined_df.to_csv(\"cluster_detailed_data.csv\", index=False)\n",
    "    print(f\"\\nResults saved to 'cluster_statistics.csv' and 'cluster_detailed_data.csv'\")\n",
    "\n",
    "else:\n",
    "    print(\"No data was successfully processed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
