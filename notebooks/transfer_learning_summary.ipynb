{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added /Users/cooper/Desktop/hydro-forecasting/src to Python path\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src directory to Python path\n",
    "project_root = Path.cwd().parent\n",
    "src_path = project_root / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "    print(f\"Added {src_path} to Python path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "from returns.result import Failure, Result, Success\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import hydro_forecasting.experiment_utils.checkpoint_manager as checkpoint_manager\n",
    "from hydro_forecasting.data.caravanify_parquet import CaravanifyParquet, CaravanifyParquetConfig\n",
    "from hydro_forecasting.data.in_memory_datamodule import HydroInMemoryDataModule\n",
    "from hydro_forecasting.model_evaluation.evaluators import TSForecastEvaluator\n",
    "from hydro_forecasting.model_evaluation.hp_from_yaml import hp_from_yaml\n",
    "from hydro_forecasting.model_evaluation.visualization import (\n",
    "    plot_basin_performance_scatter,\n",
    "    plot_horizon_performance_bars,\n",
    "    plot_model_cdf_grid,\n",
    ")\n",
    "from hydro_forecasting.models.dummy import LitRepeatLastValues, RepeatLastValuesConfig\n",
    "from hydro_forecasting.models.ealstm import EALSTMConfig, LitEALSTM\n",
    "from hydro_forecasting.models.tft import LitTFT, TFTConfig\n",
    "from hydro_forecasting.models.tide import LitTiDE, TiDEConfig\n",
    "from hydro_forecasting.models.tsmixer import LitTSMixer, TSMixerConfig\n",
    "from hydro_forecasting.preprocessing.grouped import GroupedPipeline\n",
    "from hydro_forecasting.preprocessing.normalize import NormalizeTransformer\n",
    "from hydro_forecasting.preprocessing.standard_scale import StandardScaleTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "forcing_features = [\n",
    "    \"snow_depth_water_equivalent_mean\",\n",
    "    \"surface_net_solar_radiation_mean\",\n",
    "    \"surface_net_thermal_radiation_mean\",\n",
    "    \"potential_evaporation_sum_ERA5_LAND\",\n",
    "    \"potential_evaporation_sum_FAO_PENMAN_MONTEITH\",\n",
    "    \"temperature_2m_mean\",\n",
    "    \"temperature_2m_min\",\n",
    "    \"temperature_2m_max\",\n",
    "    \"total_precipitation_sum\",\n",
    "]\n",
    "\n",
    "static_features = [\n",
    "    \"p_mean\",\n",
    "    \"area\",\n",
    "    \"ele_mt_sav\",\n",
    "    \"high_prec_dur\",\n",
    "    \"frac_snow\",\n",
    "    \"high_prec_freq\",\n",
    "    \"slp_dg_sav\",\n",
    "    \"cly_pc_sav\",\n",
    "    \"aridity_ERA5_LAND\",\n",
    "    \"aridity_FAO_PM\",\n",
    "]\n",
    "\n",
    "target = \"streamflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGIONS = [\"CA\"]\n",
    "\n",
    "COUNTRY = \"tajikistan\"\n",
    "\n",
    "MODEL_TYPES = [\n",
    "    \"tft\",\n",
    "    \"ealstm\",\n",
    "    \"tide\",\n",
    "    \"tsmixer\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following parameters were not found in the YAML file and will use defaults:\n",
      "  - hidden_continuous_size (model-specific)\n",
      "  - quantiles (model-specific)\n",
      "  - scheduler_factor (model-specific)\n",
      "  - scheduler_patience (model-specific)\n",
      "The following parameters were not found in the YAML file and will use defaults:\n",
      "  - future_forcing_projection_size (model-specific)\n",
      "  - past_feature_projection_size (model-specific)\n",
      "  - scheduler_factor (model-specific)\n",
      "  - scheduler_patience (model-specific)\n",
      "The following parameters were not found in the YAML file and will use defaults:\n",
      "  - bias (model-specific)\n",
      "  - bidirectional (model-specific)\n",
      "  - bidirectional_fusion (model-specific)\n",
      "  - future_hidden_size (model-specific)\n",
      "  - future_layers (model-specific)\n",
      "  - scheduler_factor (model-specific)\n",
      "  - scheduler_patience (model-specific)\n",
      "The following parameters were not found in the YAML file and will use defaults:\n",
      "  - scheduler_factor (model-specific)\n",
      "  - scheduler_patience (model-specific)\n"
     ]
    }
   ],
   "source": [
    "ealstm_yaml = f\"/Users/cooper/Desktop/hydro-forecasting/experiments/yaml-files/{COUNTRY.lower()}/ealstm.yaml\"\n",
    "tft_yaml = f\"/Users/cooper/Desktop/hydro-forecasting/experiments/yaml-files/{COUNTRY.lower()}/tft.yaml\"\n",
    "tide_yaml = f\"/Users/cooper/Desktop/hydro-forecasting/experiments/yaml-files/{COUNTRY.lower()}/tide.yaml\"\n",
    "tsmixer_yaml = f\"/Users/cooper/Desktop/hydro-forecasting/experiments/yaml-files/{COUNTRY.lower()}/tsmixer.yaml\"\n",
    "\n",
    "\n",
    "tft_hp = hp_from_yaml(\"tft\", tft_yaml)\n",
    "tide_hp = hp_from_yaml(\"tide\", tide_yaml)\n",
    "ealstm_hp = hp_from_yaml(\"ealstm\", ealstm_yaml)\n",
    "tsmixer_hp = hp_from_yaml(\"tsmixer\", tsmixer_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFT_config = TFTConfig(**tft_hp)\n",
    "EALSTM_config = EALSTMConfig(**ealstm_hp)\n",
    "TiDE_config = TiDEConfig(**tide_hp)\n",
    "TSMixer_config = TSMixerConfig(**tsmixer_hp)\n",
    "\n",
    "dummy_config = RepeatLastValuesConfig(\n",
    "    input_len=tide_hp[\"input_len\"],\n",
    "    input_size=tide_hp[\"input_size\"],\n",
    "    output_len=tide_hp[\"output_len\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_basin_ids(country: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Function to load basins for a given country in Central Asia\n",
    "    \"\"\"\n",
    "    # Make country lowercase and make the first letter uppercase\n",
    "    country = country.lower()\n",
    "    country = country.capitalize()\n",
    "\n",
    "    if country != \"Tajikistan\" and country != \"Kyrgyzstan\":\n",
    "        print(\"Country not supported\")\n",
    "        return []\n",
    "\n",
    "    configs = CaravanifyParquetConfig(\n",
    "        attributes_dir=\"/Users/cooper/Desktop/CaravanifyParquet/CA/post_processed/attributes\",\n",
    "        timeseries_dir=\"/Users/cooper/Desktop/CaravanifyParquet/CA/post_processed/timeseries/csv\",\n",
    "        gauge_id_prefix=\"CA\",\n",
    "        use_hydroatlas_attributes=True,\n",
    "        use_caravan_attributes=True,\n",
    "        use_other_attributes=True,\n",
    "    )\n",
    "\n",
    "    caravan = CaravanifyParquet(configs)\n",
    "    ca_basins = caravan.get_all_gauge_ids()\n",
    "    caravan.load_stations(ca_basins)\n",
    "    static_data = caravan.get_static_attributes()\n",
    "\n",
    "    return list(static_data[static_data[\"country\"] == country][\"gauge_id\"].unique())\n",
    "\n",
    "\n",
    "country_ids = load_basin_ids(COUNTRY)\n",
    "country_ids = [id for id in country_ids if id != \"CA_15030\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 total CA basins in tajikistan\n"
     ]
    }
   ],
   "source": [
    "print(f\"Found {len(country_ids)} total CA basins in {COUNTRY}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_pipeline = GroupedPipeline(\n",
    "    Pipeline([(\"scaler\", StandardScaleTransformer()), (\"normalizer\", NormalizeTransformer())]),\n",
    "    columns=forcing_features,\n",
    "    group_identifier=\"gauge_id\",\n",
    ")\n",
    "\n",
    "target_pipeline = GroupedPipeline(\n",
    "    Pipeline([(\"scaler\", StandardScaleTransformer()), (\"normalizer\", NormalizeTransformer())]),\n",
    "    columns=[\"streamflow\"],\n",
    "    group_identifier=\"gauge_id\",\n",
    ")\n",
    "\n",
    "static_pipeline = Pipeline([(\"scaler\", StandardScaleTransformer())])\n",
    "\n",
    "preprocessing_config = {\n",
    "    \"features\": {\"pipeline\": feature_pipeline},\n",
    "    \"target\": {\"pipeline\": target_pipeline},\n",
    "    \"static_features\": {\"pipeline\": static_pipeline, \"columns\": static_features},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_time_series_base_dirs = {\n",
    "    region: f\"/Users/cooper/Desktop/CaravanifyParquet/{region}/post_processed/timeseries/csv/{region}\"\n",
    "    for region in REGIONS\n",
    "}\n",
    "\n",
    "region_static_attributes_base_dirs = {\n",
    "    region: f\"/Users/cooper/Desktop/CaravanifyParquet/{region}/post_processed/attributes/{region}\" for region in REGIONS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tft_data_module = HydroInMemoryDataModule(\n",
    "    region_time_series_base_dirs=region_time_series_base_dirs,\n",
    "    region_static_attributes_base_dirs=region_static_attributes_base_dirs,\n",
    "    path_to_preprocessing_output_directory=\"/Users/cooper/Desktop/hydro-forecasting/tests/first_eval\",\n",
    "    group_identifier=\"gauge_id\",\n",
    "    batch_size=2048,\n",
    "    input_length=tft_hp[\"input_len\"],\n",
    "    output_length=tft_hp[\"output_len\"],\n",
    "    forcing_features=forcing_features,\n",
    "    static_features=static_features,\n",
    "    target=target,\n",
    "    preprocessing_configs=preprocessing_config,\n",
    "    num_workers=4,\n",
    "    min_train_years=5,\n",
    "    train_prop=0.5,\n",
    "    val_prop=0.25,\n",
    "    test_prop=0.25,\n",
    "    max_imputation_gap_size=5,\n",
    "    list_of_gauge_ids_to_process=country_ids,\n",
    "    is_autoregressive=True,\n",
    "    chunk_size=100,\n",
    "    validation_chunk_size=100,\n",
    ")\n",
    "\n",
    "tide_data_module = HydroInMemoryDataModule(\n",
    "    region_time_series_base_dirs=region_time_series_base_dirs,\n",
    "    region_static_attributes_base_dirs=region_static_attributes_base_dirs,\n",
    "    path_to_preprocessing_output_directory=\"/Users/cooper/Desktop/hydro-forecasting/tests/first_eval\",\n",
    "    group_identifier=\"gauge_id\",\n",
    "    batch_size=2048,\n",
    "    input_length=tide_hp[\"input_len\"],\n",
    "    output_length=tide_hp[\"output_len\"],\n",
    "    forcing_features=forcing_features,\n",
    "    static_features=static_features,\n",
    "    target=target,\n",
    "    preprocessing_configs=preprocessing_config,\n",
    "    num_workers=4,\n",
    "    min_train_years=5,\n",
    "    train_prop=0.5,\n",
    "    val_prop=0.25,\n",
    "    test_prop=0.25,\n",
    "    max_imputation_gap_size=5,\n",
    "    list_of_gauge_ids_to_process=country_ids,\n",
    "    is_autoregressive=True,\n",
    "    chunk_size=100,\n",
    "    validation_chunk_size=100,\n",
    ")\n",
    "\n",
    "tsmixer_data_module = HydroInMemoryDataModule(\n",
    "    region_time_series_base_dirs=region_time_series_base_dirs,\n",
    "    region_static_attributes_base_dirs=region_static_attributes_base_dirs,\n",
    "    path_to_preprocessing_output_directory=\"/Users/cooper/Desktop/hydro-forecasting/tests/first_eval\",\n",
    "    group_identifier=\"gauge_id\",\n",
    "    batch_size=2048,\n",
    "    input_length=tsmixer_hp[\"input_len\"],\n",
    "    output_length=tsmixer_hp[\"output_len\"],\n",
    "    forcing_features=forcing_features,\n",
    "    static_features=static_features,\n",
    "    target=target,\n",
    "    preprocessing_configs=preprocessing_config,\n",
    "    num_workers=4,\n",
    "    min_train_years=5,\n",
    "    train_prop=0.5,\n",
    "    val_prop=0.25,\n",
    "    test_prop=0.25,\n",
    "    max_imputation_gap_size=5,\n",
    "    list_of_gauge_ids_to_process=country_ids,\n",
    "    is_autoregressive=True,\n",
    "    chunk_size=100,\n",
    "    validation_chunk_size=100,\n",
    ")\n",
    "\n",
    "ealstm_data_module = HydroInMemoryDataModule(\n",
    "    region_time_series_base_dirs=region_time_series_base_dirs,\n",
    "    region_static_attributes_base_dirs=region_static_attributes_base_dirs,\n",
    "    path_to_preprocessing_output_directory=\"/Users/cooper/Desktop/hydro-forecasting/tests/first_eval\",\n",
    "    group_identifier=\"gauge_id\",\n",
    "    batch_size=2048,\n",
    "    input_length=ealstm_hp[\"input_len\"],\n",
    "    output_length=ealstm_hp[\"output_len\"],\n",
    "    forcing_features=forcing_features,\n",
    "    static_features=static_features,\n",
    "    target=target,\n",
    "    preprocessing_configs=preprocessing_config,\n",
    "    num_workers=4,\n",
    "    min_train_years=5,\n",
    "    train_prop=0.5,\n",
    "    val_prop=0.25,\n",
    "    test_prop=0.25,\n",
    "    max_imputation_gap_size=5,\n",
    "    list_of_gauge_ids_to_process=country_ids,\n",
    "    is_autoregressive=True,\n",
    "    chunk_size=100,\n",
    "    validation_chunk_size=100,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_checkpoint_for_model(model_type: str, checkpoint_folder: Path, select_overall_best: bool = True):\n",
    "    \"\"\"\n",
    "    Function to get the best checkpoint for a given model type\n",
    "    \"\"\"\n",
    "    result = checkpoint_manager.get_checkpoint_path_to_load(\n",
    "        base_checkpoint_load_dir=checkpoint_folder, model_type=model_type, select_overall_best=select_overall_best\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "def unwrap(checkpoint: Result) -> Path:\n",
    "    \"\"\"\n",
    "    Function to unwrap the checkpoint result\n",
    "    \"\"\"\n",
    "    if isinstance(checkpoint, Failure):\n",
    "        print(f\"Failed to load checkpoint: {checkpoint.failure()}\")\n",
    "        return None\n",
    "    elif isinstance(checkpoint, Success):\n",
    "        return checkpoint.unwrap()\n",
    "\n",
    "\n",
    "pretrained_checkpoint_dir = Path(\n",
    "    f\"/Users/cooper/Desktop/hydro-forecasting/experiments/low-medium-hii/low-medium-hii_{COUNTRY.lower()}/checkpoints\"\n",
    ")\n",
    "\n",
    "finetuned_checkpoint_dir = Path(\n",
    "    f\"/Users/cooper/Desktop/hydro-forecasting/experiments/finetune/finetune_from_low-medium-hii_{COUNTRY.lower()}/checkpoints\"\n",
    ")\n",
    "\n",
    "benchmark_checkpoint_dir = Path(\n",
    "    f\"/Users/cooper/Desktop/hydro-forecasting/experiments/benchmark/benchmark_{COUNTRY.lower()}/checkpoints\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained checkpoints: /Users/cooper/Desktop/hydro-forecasting/experiments/low-medium-hii/low-medium-hii_tajikistan/checkpoints/tide/run_0/attempt_0/tide-run0-attempt_0-epoch=75-val_loss=0.0446.ckpt, /Users/cooper/Desktop/hydro-forecasting/experiments/low-medium-hii/low-medium-hii_tajikistan/checkpoints/ealstm/run_0/attempt_0/ealstm-run0-attempt_0-epoch=43-val_loss=0.0924.ckpt, /Users/cooper/Desktop/hydro-forecasting/experiments/low-medium-hii/low-medium-hii_tajikistan/checkpoints/tsmixer/run_0/attempt_0/tsmixer-run0-attempt_0-epoch=41-val_loss=0.0934.ckpt, /Users/cooper/Desktop/hydro-forecasting/experiments/low-medium-hii/low-medium-hii_tajikistan/checkpoints/tft/run_0/attempt_0/tft-run0-attempt_0-epoch=154-val_loss=0.0380.ckpt\n",
      "Finetuned checkpoints: /Users/cooper/Desktop/hydro-forecasting/experiments/finetune/finetune_from_low-medium-hii_tajikistan/checkpoints/tide/run_3/attempt_0/tide-run3-attempt_0-epoch=13-val_loss=0.0298.ckpt, /Users/cooper/Desktop/hydro-forecasting/experiments/finetune/finetune_from_low-medium-hii_tajikistan/checkpoints/ealstm/run_4/attempt_0/ealstm-run4-attempt_0-epoch=01-val_loss=0.0258.ckpt, /Users/cooper/Desktop/hydro-forecasting/experiments/finetune/finetune_from_low-medium-hii_tajikistan/checkpoints/tsmixer/run_0/attempt_0/tsmixer-run0-attempt_0-epoch=11-val_loss=0.0270.ckpt, /Users/cooper/Desktop/hydro-forecasting/experiments/finetune/finetune_from_low-medium-hii_tajikistan/checkpoints/tft/run_0/attempt_0/tft-run0-attempt_0-epoch=49-val_loss=0.0273.ckpt\n",
      "Benchmark checkpoints: /Users/cooper/Desktop/hydro-forecasting/experiments/benchmark/benchmark_tajikistan/checkpoints/tide/run_3/attempt_0/tide-run3-attempt_0-epoch=67-val_loss=0.0361.ckpt, /Users/cooper/Desktop/hydro-forecasting/experiments/benchmark/benchmark_tajikistan/checkpoints/ealstm/run_2/attempt_0/ealstm-run2-attempt_0-epoch=12-val_loss=0.0345.ckpt, /Users/cooper/Desktop/hydro-forecasting/experiments/benchmark/benchmark_tajikistan/checkpoints/tsmixer/run_0/attempt_0/tsmixer-run0-attempt_0-epoch=28-val_loss=0.0395.ckpt, /Users/cooper/Desktop/hydro-forecasting/experiments/benchmark/benchmark_tajikistan/checkpoints/tft/run_2/attempt_0/tft-run2-attempt_0-epoch=197-val_loss=0.0341.ckpt\n"
     ]
    }
   ],
   "source": [
    "tft_pretrained_checkpoint = unwrap(\n",
    "    get_checkpoint_for_model(\n",
    "        model_type=\"tft\",\n",
    "        checkpoint_folder=pretrained_checkpoint_dir,\n",
    "        select_overall_best=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "tide_pretrained_checkpoint = unwrap(\n",
    "    get_checkpoint_for_model(\n",
    "        model_type=\"tide\",\n",
    "        checkpoint_folder=pretrained_checkpoint_dir,\n",
    "        select_overall_best=True,\n",
    "    )\n",
    ")\n",
    "ealstm_pretrained_checkpoint = unwrap(\n",
    "    get_checkpoint_for_model(\n",
    "        model_type=\"ealstm\",\n",
    "        checkpoint_folder=pretrained_checkpoint_dir,\n",
    "        select_overall_best=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "tsmixer_pretrained_checkpoint = unwrap(\n",
    "    get_checkpoint_for_model(\n",
    "        model_type=\"tsmixer\",\n",
    "        checkpoint_folder=pretrained_checkpoint_dir,\n",
    "        select_overall_best=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "tft_finetuned_checkpoint = unwrap(\n",
    "    get_checkpoint_for_model(\n",
    "        model_type=\"tft\",\n",
    "        checkpoint_folder=finetuned_checkpoint_dir,\n",
    "        select_overall_best=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "tide_finetuned_checkpoint = unwrap(\n",
    "    get_checkpoint_for_model(\n",
    "        model_type=\"tide\",\n",
    "        checkpoint_folder=finetuned_checkpoint_dir,\n",
    "        select_overall_best=True,\n",
    "    )\n",
    ")\n",
    "ealstm_finetuned_checkpoint = unwrap(\n",
    "    get_checkpoint_for_model(\n",
    "        model_type=\"ealstm\",\n",
    "        checkpoint_folder=finetuned_checkpoint_dir,\n",
    "        select_overall_best=True,\n",
    "    )\n",
    ")\n",
    "tsmixer_finetuned_checkpoint = unwrap(\n",
    "    get_checkpoint_for_model(\n",
    "        model_type=\"tsmixer\",\n",
    "        checkpoint_folder=finetuned_checkpoint_dir,\n",
    "        select_overall_best=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "tft_benchmark_checkpoint = unwrap(\n",
    "    get_checkpoint_for_model(\n",
    "        model_type=\"tft\",\n",
    "        checkpoint_folder=benchmark_checkpoint_dir,\n",
    "        select_overall_best=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "tide_benchmark_checkpoint = unwrap(\n",
    "    get_checkpoint_for_model(\n",
    "        model_type=\"tide\",\n",
    "        checkpoint_folder=benchmark_checkpoint_dir,\n",
    "        select_overall_best=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "ealstm_benchmark_checkpoint = unwrap(\n",
    "    get_checkpoint_for_model(\n",
    "        model_type=\"ealstm\",\n",
    "        checkpoint_folder=benchmark_checkpoint_dir,\n",
    "        select_overall_best=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "tsmixer_benchmark_checkpoint = unwrap(\n",
    "    get_checkpoint_for_model(\n",
    "        model_type=\"tsmixer\",\n",
    "        checkpoint_folder=benchmark_checkpoint_dir,\n",
    "        select_overall_best=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Pretrained checkpoints: {tide_pretrained_checkpoint}, {ealstm_pretrained_checkpoint}, {tsmixer_pretrained_checkpoint}, {tft_pretrained_checkpoint}\"\n",
    ")\n",
    "print(\n",
    "    f\"Finetuned checkpoints: {tide_finetuned_checkpoint}, {ealstm_finetuned_checkpoint}, {tsmixer_finetuned_checkpoint}, {tft_finetuned_checkpoint}\"\n",
    ")\n",
    "print(\n",
    "    f\"Benchmark checkpoints: {tide_benchmark_checkpoint}, {ealstm_benchmark_checkpoint}, {tsmixer_benchmark_checkpoint}, {tft_benchmark_checkpoint}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = LitRepeatLastValues(config=dummy_config)\n",
    "ealstm_benchmark_model = LitEALSTM.load_from_checkpoint(ealstm_benchmark_checkpoint, config=EALSTM_config)\n",
    "tide_benchmark_model = LitTiDE.load_from_checkpoint(tide_benchmark_checkpoint, config=TiDE_config)\n",
    "tsmixer_benchmark_model = LitTSMixer.load_from_checkpoint(tsmixer_benchmark_checkpoint, config=TSMixer_config)\n",
    "tft_benchmark_model = LitTFT.load_from_checkpoint(tft_benchmark_checkpoint, config=TFT_config)\n",
    "\n",
    "ealstm_pretrained_model = LitEALSTM.load_from_checkpoint(ealstm_pretrained_checkpoint, config=EALSTM_config)\n",
    "tide_pretrained_model = LitTiDE.load_from_checkpoint(tide_pretrained_checkpoint, config=TiDE_config)\n",
    "tsmixer_pretrained_model = LitTSMixer.load_from_checkpoint(tsmixer_pretrained_checkpoint, config=TSMixer_config)\n",
    "tft_pretrained_model = LitTFT.load_from_checkpoint(tft_pretrained_checkpoint, config=TFT_config)\n",
    "\n",
    "ealstm_finetuned_model = LitEALSTM.load_from_checkpoint(ealstm_finetuned_checkpoint, config=EALSTM_config)\n",
    "tide_finetuned_model = LitTiDE.load_from_checkpoint(tide_finetuned_checkpoint, config=TiDE_config)\n",
    "tsmixer_finetuned_model = LitTSMixer.load_from_checkpoint(tsmixer_finetuned_checkpoint, config=TSMixer_config)\n",
    "tft_finetuned_model = LitTFT.load_from_checkpoint(tft_finetuned_checkpoint, config=TFT_config)\n",
    "\n",
    "\n",
    "# Create a dictionary mapping model names to (model, datamodule) tuples\n",
    "models_and_datamodules = {\n",
    "    \"ealstm_benchmark\": (ealstm_benchmark_model, ealstm_data_module),\n",
    "    \"ealstm_pretrained\": (ealstm_pretrained_model, ealstm_data_module),\n",
    "    \"ealstm_finetuned\": (ealstm_finetuned_model, ealstm_data_module),\n",
    "    # \"tide_benchmark\": (tide_benchmark_model, tide_data_module),\n",
    "    # \"tide_pretrained\": (tide_pretrained_model, tide_data_module),\n",
    "    # \"tide_finetuned\": (tide_finetuned_model, tide_data_module),\n",
    "    # \"tsmixer_benchmark\": (tsmixer_benchmark_model, tsmixer_data_module),\n",
    "    # \"tsmixer_pretrained\": (tsmixer_pretrained_model, tsmixer_data_module),\n",
    "    # \"tsmixer_finetuned\": (tsmixer_finetuned_model, tsmixer_data_module),\n",
    "    # \"tft_benchmark\": (tft_benchmark_model, tft_data_module),\n",
    "    # \"tft_pretrained\": (tft_pretrained_model, tft_data_module),\n",
    "    # \"tft_finetuned\": (tft_finetuned_model, tft_data_module),\n",
    "    # \"dummy\": (dummy_model, tft_data_module),\n",
    "}\n",
    "\n",
    "\n",
    "evaluator = TSForecastEvaluator(\n",
    "    horizons=list(range(1, 11)),\n",
    "    models_and_datamodules=models_and_datamodules,\n",
    "    trainer_kwargs={\"accelerator\": \"cpu\", \"devices\": 1, \"deterministic\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ealstm_benchmark...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d79a6ede85d46a58ef798b445d7ff5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.04063325747847557\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ealstm_pretrained...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59171afb82a449c1978c7623ef7592dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.03823389858007431\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ealstm_finetuned...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d46cda3de4d488787733120568879bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.03162413835525513\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ealstm_benchmark...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8801737b5b2e4b16ac50b2b08887fffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss          0.039664704352617264\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ealstm_pretrained...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475fc489de174b3c8bcc1ea3fc31adab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.03713880479335785\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ealstm_finetuned...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cooper/Desktop/hydro-forecasting/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b017ce591fa243d3906a19f09d2e09ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.03169454261660576\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "# Run this twice and see if results differ\n",
    "results1 = evaluator.test_models()\n",
    "results2 = evaluator.test_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First run NSE: nan\n",
      "Second run NSE: nan\n"
     ]
    }
   ],
   "source": [
    "# Compare a specific metric\n",
    "model_name = \"ealstm_benchmark\"  # Pick any model\n",
    "print(\"First run NSE:\", results1[model_name][\"metrics\"][5][\"NSE\"])\n",
    "print(\"Second run NSE:\", results2[model_name][\"metrics\"][5][\"NSE\"])\n",
    "\n",
    "# Reset model states between runs\n",
    "for name, model in evaluator.models.items():\n",
    "    model.eval()  # Ensure eval mode\n",
    "    if hasattr(model, 'reset_parameters'):\n",
    "        model.reset_parameters()\n",
    "\n",
    "# Compare test dataloaders between runs\n",
    "dl1 = evaluator.datamodules[\"ealstm_benchmark\"].test_dataloader()\n",
    "dl2 = evaluator.datamodules[\"ealstm_benchmark\"].test_dataloader()\n",
    "# Check if they produce identical batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(results1[\"ealstm_benchmark\"][\"df\"][\"prediction\"] != results2[\"ealstm_benchmark\"][\"df\"][\"prediction\"]))\n",
    "print(sum(results1[\"ealstm_benchmark\"][\"df\"][\"observed\"] != results2[\"ealstm_benchmark\"][\"df\"][\"observed\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run evaluation\n",
    "# results = evaluator.test_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "def filter_growing_season_polars(eval_results: dict[str, Any]) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Filter evaluation results to include only data from the growing season (April to October), using Polars.\n",
    "\n",
    "    Args:\n",
    "        eval_results: dictionary containing evaluation results with a 'df' key,\n",
    "                      where 'df' is a Polars DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        dictionary with filtered Polars DataFrame and original metrics.\n",
    "    \"\"\"\n",
    "    filtered_results = eval_results.copy()\n",
    "\n",
    "    df = eval_results[\"df\"].clone()\n",
    "\n",
    "    if \"date\" not in df.columns:\n",
    "        raise ValueError(\"DataFrame must contain a 'date' column.\")\n",
    "\n",
    "    growing_season_df = df.filter((pl.col(\"date\").dt.month() >= 4) & (pl.col(\"date\").dt.month() <= 9))\n",
    "\n",
    "    growing_season_df = df.filter((pl.col(\"date\").dt.month() >= 4) & (pl.col(\"date\").dt.month() < 10))\n",
    "\n",
    "    filtered_results[\"df\"] = growing_season_df\n",
    "\n",
    "    return filtered_results\n",
    "\n",
    "\n",
    "def process_seasonal_results_polars(\n",
    "    results: dict[str, Any],\n",
    "    evaluator: Any,  # Replace Any with the actual type of TSForecastEvaluator if available\n",
    "    model_keys: list[str] = None,\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Process specified model results to get seasonal metrics using Polars DataFrames.\n",
    "\n",
    "    Args:\n",
    "        results: dictionary containing results for all models.\n",
    "        evaluator: Evaluator object with _calculate_overall_metrics and\n",
    "                   _calculate_basin_metrics methods that can handle Polars DataFrames.\n",
    "                   (As per evaluators.py, these methods already use Polars)\n",
    "        model_keys: list of model keys to process. If None, process all keys in results.\n",
    "\n",
    "    Returns:\n",
    "        dictionary with seasonal results for the specified models.\n",
    "    \"\"\"\n",
    "    seasonal_results = {}\n",
    "\n",
    "    if model_keys is None:\n",
    "        model_keys = list(results.keys())\n",
    "\n",
    "    # Process each model\n",
    "    for key in model_keys:\n",
    "        if key not in results:\n",
    "            print(f\"Warning: Model key '{key}' not found in results. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Filter for growing season using the Polars version\n",
    "        seasonal_model_results = filter_growing_season_polars(results[key])\n",
    "\n",
    "        seasonal_model_results[\"metrics\"] = evaluator._calculate_overall_metrics(seasonal_model_results[\"df\"])\n",
    "        seasonal_model_results[\"basin_metrics\"] = evaluator._calculate_basin_metrics(seasonal_model_results[\"df\"])\n",
    "\n",
    "        # Store in results dictionary\n",
    "        seasonal_results[key] = seasonal_model_results\n",
    "\n",
    "    return seasonal_results\n",
    "\n",
    "\n",
    "seasonal_results = process_seasonal_results_polars(results, evaluator, model_keys=list(models_and_datamodules.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(context=\"paper\", font_scale=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_horizon_performance_bars(\n",
    "    seasonal_results,\n",
    "    horizon=10,\n",
    "    metric=\"NSE\",\n",
    "    architectures=[\"tide\", \"ealstm\", \"tsmixer\", \"tft\"],\n",
    "    variants=[\"benchmark\", \"pretrained\", \"finetuned\"],\n",
    "    colors={\"tide\": \"#4682B4\", \"ealstm\": \"#CD5C5C\", \"tsmixer\": \"#009E73\", \"tft\": \"#9370DB\"},\n",
    "    figsize=(12, 5),\n",
    "    with_whiskers=False,\n",
    "    positive_is_better=True\n",
    ")\n",
    "ax.set_ylim(0, 1)\n",
    "sns.despine()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_basin_performance_scatter(\n",
    "    seasonal_results,\n",
    "    benchmark_pattern=\"pretrained\",\n",
    "    challenger_pattern=\"finetuned\",\n",
    "    horizon=10,\n",
    "    architectures=[\"tide\", \"ealstm\", \"tsmixer\", \"tft\"],\n",
    "    metric=\"NSE\",\n",
    "    figsize=(10, 6),\n",
    "    colors={\"tide\": \"#4682B4\", \"ealstm\": \"#CD5C5C\", \"tsmixer\": \"#009E73\", \"tft\": \"#9370DB\"},\n",
    "    debug=False,\n",
    ")\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plot_model_cdf_grid(\n",
    "    seasonal_results,\n",
    "    horizons=[1, 5, 10],\n",
    "    metric=\"NSE\",\n",
    "    architectures=[\"tide\", \"ealstm\", \"tsmixer\", \"tft\"],\n",
    "    variants=[\"benchmark\", \"finetuned\"],\n",
    "    colors={\"tide\": \"#4682B4\", \"ealstm\": \"#CD5C5C\", \"tsmixer\": \"#009E73\", \"tft\": \"#9370DB\"},\n",
    "    figsize=(10, 7),\n",
    ")\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
