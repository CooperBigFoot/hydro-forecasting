# Instructions for LLM Code Generation in Hydrological Time Series Analysis

## Project Overview

This project focuses on hydrological modeling using deep learning techniques to analyze rainfall-runoff dynamics. It leverages time series data from various catchments to build models that can transfer knowledge between regions (e.g., from data-rich European basins to data-sparse Central Asian basins). The core objective is to improve hydrological predictions in both gauged and ungauged basins through various deep learning architectures including LSTMs, EA-LSTMs, and TSMixer models.

## Tech Stack

- **Python 3.10**: Core language
- **PyTorch & PyTorch Lightning**: Deep learning framework
- **polars**: Primary data manipulation library
- **pandas**: Used for prototyping in notebooks
- **NumPy**: Numerical computations
- **scikit-learn**: Preprocessing pipelines and metrics
- **dtwcluster/dtaidistance**: Time series clustering with Dynamic Time Warping
- **Matplotlib & Seaborn**: Visualization
- **returns**: Functional error handling with Railway Oriented Programming
- **pytest**: Testing framework

## Code Generation Guidelines

### Structure and Style

1. Use clear, descriptive variable and function names that reflect hydrological domain concepts.
2. Structure code into logical modules: data loading, preprocessing, modeling, evaluation.
3. Adhere to PEP 8 conventions with consistent spacing and line length.
4. Include necessary imports at the top of each file.
5. Place all documentation files in the `docs/` directory.

### Type Hints

Python 3.12 introduces enhanced type hinting features. When generating or refactoring code:

1. **Use Built-in Generics**: Prefer `list`, `dict`, `tuple`, and `set` over legacy `List`, `Dict`, `Tuple`, and `Set` from the `typing` module. These are now standard and more readable.

   ```python
   def summarize_flows(flows: list[float]) -> dict[str, float]:
       ...
   ```

### Railway Oriented Programming with `returns`

Implement functional error handling using the `returns` package:

1. **Use `Result` Containers**: Wrap operations that may fail in `Result` containers to handle success and failure paths explicitly.

   ```python
   from returns.result import Result, Success, Failure

   def divide(a: float, b: float) -> Result[float, str]:
       if b == 0:
           return Failure("Division by zero")
       return Success(a / b)
   ```

2. **Chaining Operations**: Use `.map()` for transforming successful results and `.bind()` for chaining operations that return `Result`.

   ```python
   result = divide(10, 2).map(lambda x: x * 2)
   ```

3. **Error Handling**: Utilize `.alt()` to transform errors and `.rescue()` to recover from failures.

   ```python
   result = divide(10, 0).alt(lambda e: f"Error occurred: {e}")
   ```

4. **Avoid Exceptions**: Prefer `Result` containers over exceptions for predictable error handling.

### Testing with `pytest`

1. **Test Structure**: Organize tests in a `tests/` directory, mirroring the project structure.

2. **Test Functions**: Write test functions prefixed with `test_` and use assertions to validate behavior.

   ```python
   def test_divide_success():
       assert divide(10, 2) == Success(5.0)
   ```

3. **Fixtures**: Use `pytest` fixtures for setting up common test data.

4. **Coverage**: Aim for high test coverage, especially for critical components.

### Docstrings

1. **Format**: Use Google-style docstrings with sections for Args, Returns, and Raises.

2. **Content**: Provide concise descriptions of function behavior, parameters, return values, and exceptions.

3. **Examples**: Include usage examples for complex functions.

   ```python
   def apply_log_transform(
       df: pl.DataFrame,
       columns: list[str],
       epsilon: float = 1e-8
   ) -> pl.DataFrame:
       """
       Apply log1p transform to specified columns with epsilon handling.

       Args:
           df: Input DataFrame containing time series data.
           columns: Column names to transform.
           epsilon: Small constant to add before transform to handle zeros.

       Returns:
           DataFrame with transformed values.

       Raises:
           ValueError: If any column is not found in the DataFrame.
       """
       # Implementation here
   ```
