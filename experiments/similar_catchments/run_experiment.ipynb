{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f2fc10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter lab build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "659bed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.disable(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f65efe2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from hydro_forecasting.experiment_utils.train_model_from_scratch import train_model_from_scratch\n",
    "from hydro_forecasting.preprocessing.pipeline_builder import PipelineBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7c3393",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab68b34",
   "metadata": {},
   "source": [
    "## Experiment constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a6885fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGIONS = [\n",
    "    \"CL\",\n",
    "    \"CH\",\n",
    "    \"USA\",\n",
    "    # \"camelsaus\",\n",
    "    # \"camelsgb\",\n",
    "    # \"camelsbr\",\n",
    "    # \"hysets\",\n",
    "    # \"lamah\",\n",
    "]\n",
    "\n",
    "COUNTRY = \"tajikistan\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2533b81f",
   "metadata": {},
   "source": [
    "## Loading the data (as gauge_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed0ce646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2929 basins in clusters [2, 7]\n"
     ]
    }
   ],
   "source": [
    "def load_basin_ids(cluster_list):\n",
    "    \"\"\"\n",
    "    Returns the gauge IDs of basins that belong to the specified clusters.\n",
    "\n",
    "    Args:\n",
    "        cluster_df: DataFrame with gauge_id and cluster columns\n",
    "        cluster_list: List of cluster numbers to filter by\n",
    "\n",
    "    Returns:\n",
    "        List of gauge_ids in the specified clusters\n",
    "    \"\"\"\n",
    "    path_to_clustering_results = \"/workspace/hydro-forecasting/scripts/cluster_basins/clustering_results/cluster_assignments_shifted_refactor.csv\"\n",
    "    cluster_df = pd.read_csv(path_to_clustering_results)\n",
    "\n",
    "    filtered_df = cluster_df[cluster_df[\"cluster\"].isin(cluster_list)]\n",
    "\n",
    "    basin_ids = filtered_df[\"gauge_id\"].tolist()\n",
    "\n",
    "    print(f\"Found {len(basin_ids)} basins in clusters {cluster_list}\")\n",
    "\n",
    "    return basin_ids\n",
    "\n",
    "\n",
    "basin_ids = load_basin_ids([2, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f9edf0",
   "metadata": {},
   "source": [
    "## Datamodule Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2ea76fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_time_series_base_dirs = {\n",
    "    region: f\"/workspace/CaravanifyParquet/{region}/post_processed/timeseries/csv/{region}\" for region in REGIONS\n",
    "}\n",
    "\n",
    "region_static_attributes_base_dirs = {\n",
    "    region: f\"/workspace/CaravanifyParquet/{region}/post_processed/attributes/{region}\" for region in REGIONS\n",
    "}\n",
    "\n",
    "path_to_preprocessing_output_directory = \"/workspace/hydro-forecasting/experiments/similar_catchments/data_cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f14911d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "forcing_features = [\n",
    "    \"snow_depth_water_equivalent_mean\",\n",
    "    \"surface_net_solar_radiation_mean\",\n",
    "    \"surface_net_thermal_radiation_mean\",\n",
    "    \"potential_evaporation_sum_ERA5_LAND\",\n",
    "    \"potential_evaporation_sum_FAO_PENMAN_MONTEITH\",\n",
    "    \"temperature_2m_mean\",\n",
    "    \"temperature_2m_min\",\n",
    "    \"temperature_2m_max\",\n",
    "    \"total_precipitation_sum\",\n",
    "]\n",
    "\n",
    "static_features = [\n",
    "    \"p_mean\",\n",
    "    \"area\",\n",
    "    \"ele_mt_sav\",\n",
    "    \"high_prec_dur\",\n",
    "    \"frac_snow\",\n",
    "    \"high_prec_freq\",\n",
    "    \"slp_dg_sav\",\n",
    "    \"cly_pc_sav\",\n",
    "    \"aridity_ERA5_LAND\",\n",
    "    \"aridity_FAO_PM\",\n",
    "]\n",
    "\n",
    "target = \"streamflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "962da35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pipeline', 'strategy', 'columns'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder = PipelineBuilder()\n",
    "\n",
    "feature_section = (\n",
    "    builder.features().transforms([\"standard_scale\"]).strategy(\"unified\").columns(forcing_features)\n",
    ")\n",
    "\n",
    "target_section = (\n",
    "    builder.target()\n",
    "    .transforms([\"log_scale\", \"standard_scale\"])\n",
    "    .strategy(\"per_group\", group_by=\"gauge_id\")\n",
    "    .columns([target])\n",
    ")\n",
    "\n",
    "static_section = builder.static_features().transforms([\"standard_scale\"]).strategy(\"unified\").columns(static_features)\n",
    "\n",
    "preprocessing_config = builder.build()\n",
    "\n",
    "preprocessing_config[\"static_features\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd0f0b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule_config = {\n",
    "    \"region_time_series_base_dirs\": region_time_series_base_dirs,\n",
    "    \"region_static_attributes_base_dirs\": region_static_attributes_base_dirs,\n",
    "    \"path_to_preprocessing_output_directory\": path_to_preprocessing_output_directory,\n",
    "    \"group_identifier\": \"gauge_id\",\n",
    "    \"batch_size\": 2048,\n",
    "    \"forcing_features\": forcing_features,\n",
    "    \"static_features\": static_features,\n",
    "    \"target\": target,\n",
    "    \"num_workers\": 12,\n",
    "    \"min_train_years\": 10,\n",
    "    \"train_prop\": 0.5,\n",
    "    \"val_prop\": 0.25,\n",
    "    \"test_prop\": 0.25,\n",
    "    \"max_imputation_gap_size\": 5,\n",
    "    \"chunk_size\": 1500,\n",
    "    \"validation_chunk_size\": 4000,\n",
    "    \"is_autoregressive\": True,\n",
    "    \"preprocessing_configs\": preprocessing_config,\n",
    "    \"random_seed\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158363b3",
   "metadata": {},
   "source": [
    "## Training Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9709710c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = {\n",
    "    \"max_epochs\": 300,\n",
    "    \"accelerator\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"devices\": 1,\n",
    "    \"early_stopping_patience\": 15,\n",
    "    \"reload_dataloaders_every_n_epochs\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38258592",
   "metadata": {},
   "source": [
    "## Remaining Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2274e894",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/workspace/hydro-forecasting/experiments/similar_catchments\"\n",
    "model_types = [\"tide\", \"ealstm\", \"tsmixer\", \"tft\"]\n",
    "\n",
    "yaml_paths = [\n",
    "    f\"/workspace/hydro-forecasting/experiments/yaml-files/unified/{COUNTRY}/tide.yaml\",\n",
    "    f\"/workspace/hydro-forecasting/experiments/yaml-files/unified/{COUNTRY}/ealstm.yaml\",\n",
    "    f\"/workspace/hydro-forecasting/experiments/yaml-files/unified/{COUNTRY}/tsmixer.yaml\",\n",
    "    f\"/workspace/hydro-forecasting/experiments/yaml-files/unified/{COUNTRY}/tft.yaml\",\n",
    "]\n",
    "experiment_name = f\"similar-catchments_unified_with_RevIN_{COUNTRY}\"\n",
    "num_runs = 1\n",
    "override_previous_attempts = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb369289",
   "metadata": {},
   "source": [
    "## Training the models from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1054c874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following parameters were not found in the YAML file and will use defaults:\n",
      "  - future_forcing_projection_size (model-specific)\n",
      "  - past_feature_projection_size (model-specific)\n",
      "  - scheduler_factor (model-specific)\n",
      "  - scheduler_patience (model-specific)\n",
      "  - use_rev_in (standard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3555dc1fc0d447784f59a9b8c81f570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a101c4a779a44704b1163480f9550ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "227decc88a1e4b8a8022d81c108e1f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_results = train_model_from_scratch(\n",
    "    gauge_ids=basin_ids,\n",
    "    datamodule_config=datamodule_config,\n",
    "    training_config=training_config,\n",
    "    output_dir=output_dir,\n",
    "    model_types=model_types,\n",
    "    yaml_paths=yaml_paths,\n",
    "    experiment_name=experiment_name,\n",
    "    num_runs=num_runs,\n",
    "    override_previous_attempts=override_previous_attempts,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
